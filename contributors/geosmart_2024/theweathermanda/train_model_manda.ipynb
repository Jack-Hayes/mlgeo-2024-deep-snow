{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a54d384-100e-4f91-b8b0-44ce430c3e8e",
   "metadata": {},
   "source": [
    "# Train a model on the crunchy-snow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a72193-b73a-4e2e-b4f0-479a50da7cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = '/home/jovyan/crunchy-snow'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cec9d23-fc50-49a4-9114-207df25d51b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cff279-de3d-4761-99df-0433d48569ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(parent_dir)\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98330207-9f48-4ba1-b9e4-d4af4c374b57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!mamba env create -f environment.yml \n",
    "!conda init\n",
    "!conda activate crunchy-snow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2588aa-e7f3-4d02-9bef-039873704ec6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a93e0af5-5251-47ba-853b-6d43867dca3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m glob\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m                   \u001b[38;5;66;03m# Package for implementing various optimization algorithms\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim                   # Package for implementing various optimization algorithms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F               # Functions (convolution, activation, loss, etc.)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import crunchy_snow.models\n",
    "import crunchy_snow.dataset\n",
    "\n",
    "import sklearn.metrics as skmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36657942-91eb-4fa9-bf47-971280c524e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Available device: {available_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e92c7aa-498d-49d9-b2a7-c1700f0f018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag for whether GPUs are available\n",
    "\n",
    "if available_device == 'cuda':\n",
    "    gpus = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa768b49-c7ea-4b12-84bb-5f4628113110",
   "metadata": {},
   "source": [
    "## Prepare dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981de39d-c6cb-4f85-9f11-26ad0785d9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get paths to data\n",
    "train_data_dir = '/home/jovyan/shared-public/crunchy-snow/data/subsets_v3/train'\n",
    "train_path_list = glob(f'{train_data_dir}/ASO_50M_SD*.nc')\n",
    "\n",
    "val_data_dir = '/home/jovyan/shared-public/crunchy-snow/data/subsets_v3/val'\n",
    "val_path_list = glob(f'{val_data_dir}/ASO_50M_SD*.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b4cf07-2a33-4ea4-8ce8-60d6e416c9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c83864-1f91-499c-ba3d-4bbd97fb08cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52738d11-e34f-4af7-8088-c1775076997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to test code with a small sample of the data\n",
    "import random\n",
    "random.seed(10)\n",
    "\n",
    "n_imgs = 100 # 16\n",
    "\n",
    "train_path_list = random.sample(train_path_list, n_imgs)\n",
    "val_path_list = random.sample(val_path_list, n_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe8cd93-40cd-49ce-8d18-060bd4c8aa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data to be returned by dataloader\n",
    "selected_channels = [\n",
    "    # ASO products\n",
    "    'aso_sd', # ASO lidar snow depth (target dataset)\n",
    "    'aso_gap_map', # gaps in ASO data\n",
    "    \n",
    "    # Sentinel-1 products\n",
    "    'snowon_vv', # snow on Sentinel-1 VV polarization backscatter in dB, closest acquisition to ASO acquisition\n",
    "    'snowon_vh', # snow on Sentinel-1 VH polarization backscatter in dB, closest acquisition to ASO acquisition\n",
    "    'snowoff_vv', # snow off Sentinel-1 VV polarization backscatter in dB, closest acquisition to ASO acquisition\n",
    "    'snowoff_vh', # snow off Sentinel-1 VH polarization backscatter in dB, closest acquisition to ASO acquisition\n",
    "    'snowon_vv_mean', # snow on Sentinel-1 VV polarization backscatter in dB, mean of acquisition in 4 week period around ASO acquisition\n",
    "    'snowon_vh_mean', # snow on Sentinel-1 VH polarization backscatter in dB, mean of acquisition in 4 week period around ASO acquisition\n",
    "    'snowoff_vv_mean', # snow off Sentinel-1 VV polarization backscatter in dB, mean of acquisition in 4 week period around ASO acquisition\n",
    "    'snowoff_vh_mean', # snow off Sentinel-1 VH polarization backscatter in dB, mean of acquisition in 4 week period around ASO acquisition\n",
    "    'snowon_cr', # cross ratio, snowon_vh - snowon_vv\n",
    "    'snowoff_cr', # cross ratio, snowoff_vh - snowoff_vv\n",
    "    'delta_cr', # change in cross ratio, snowon_cr - snowoff_cr\n",
    "    'rtc_gap_map', # gaps in Sentinel-1 data\n",
    "    'rtc_mean_gap_map', # gaps in Sentinel-1 mean data\n",
    "    \n",
    "    # Sentinel-2 products \n",
    "    'aerosol_optical_thickness', # snow on Sentinel-2 aerosol optical thickness band \n",
    "    'coastal_aerosol', # snow on Sentinel-2 coastal aerosol band\n",
    "    'blue', # snow on Sentinel-2 blue band\n",
    "    'green', # snow on Sentinel-2 green band\n",
    "    'red', # snow on Sentinel-2 red band\n",
    "    'red_edge1', # snow on Sentinel-2 red edge 1 band\n",
    "    'red_edge2', # snow on Sentinel-2 red edge 2 band\n",
    "    'red_edge3', # snow on Sentinel-2 red edge 3 band\n",
    "    'nir', # snow on Sentinel-2 near infrared band\n",
    "    'water_vapor', # snow on Sentinel-2 water vapor\n",
    "    'swir1', # snow on Sentinel-2 shortwave infrared band 1\n",
    "    'swir2', # snow on Sentinel-2 shortwave infrared band 2\n",
    "    'scene_class_map', # snow on Sentinel-2 scene classification product\n",
    "    'water_vapor_product', # snow on Sentinel-2 water vapor product\n",
    "    'ndvi', # Normalized Difference Vegetation Index from Sentinel-2\n",
    "    'ndsi', # Normalized Difference Snow Index from Sentinel-2\n",
    "    'ndwi', # Normalized Difference Water Index from Sentinel-2\n",
    "    's2_gap_map', # gaps in Sentinel-2 data\n",
    "\n",
    "    # PROBA-V global land cover dataset (Buchhorn et al., 2020)\n",
    "    'fcf', # fractional forest cover\n",
    "    \n",
    "    # COP30 digital elevation model      \n",
    "    'elevation',\n",
    "\n",
    "    # latitude and longitude\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "\n",
    "    # day of water year\n",
    "    'dowy'\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d12c638-c05d-4162-8405-2c3669ccb1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training and validation dataloaders\n",
    "\n",
    "train_batch = 16\n",
    "\n",
    "train_data = crunchy_snow.dataset.Dataset(train_path_list, selected_channels, norm=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=train_batch, shuffle=False)\n",
    "\n",
    "val_data = crunchy_snow.dataset.Dataset(val_path_list, selected_channels, norm=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae51cf91-3f96-4541-b264-1d8c23f859de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(selected_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0c867b-36a4-4719-9320-3aa19b0766bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input channels for model\n",
    "input_channels = [\n",
    "    'snowon_vv',\n",
    "    'snowon_vh',\n",
    "    'snowoff_vv',\n",
    "    'snowoff_vh',\n",
    "    'blue',\n",
    "    'green',\n",
    "    'red',\n",
    "    'fcf',\n",
    "    'elevation',\n",
    "    'ndvi',\n",
    "    'ndsi',\n",
    "    'ndwi',\n",
    "    'snowon_cr',\n",
    "    'snowoff_cr',\n",
    "    'scene_class_map' # new var\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0d67bb-6422-4f54-8b34-ffa5cbee346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "omitted_channels = np.setdiff1d(selected_channels,input_channels)\n",
    "print(omitted_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b36322-9ac5-4a3f-aefa-98ad371d1ee0",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aebf81-be4e-4200-ab12-70168b8eb37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model\n",
    "# model = crunchy_snow.models.SimpleCNN(n_input_channels=len(input_channels))\n",
    "#model = crunchy_snow.models.UNet(n_input_channels=len(input_channels))           \n",
    "# model = crunchy_snow.models.ResUNet(n_input_channels=len(input_channels))                # predicted fields are smooth\n",
    "model = crunchy_snow.models.ResDepth(n_input_channels=len(input_channels))\n",
    "# model = crunchy_snow.models.VisionTransformer(n_input_channels=len(input_channels))      # predicted fields are noisy\n",
    "\n",
    "if gpus == True:\n",
    "    model.to('cuda');  # Run on GPU\n",
    "\n",
    "# name your model\n",
    "model_name = 'mandachasteen_ResDepth_sceneclassmap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da4e4b7-5679-4e71-b1c3-664346b40060",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define optimizer and loss function\n",
    "\n",
    "learning_rate = 0.0003\n",
    "epochs = 16\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "# training and validation loop\n",
    "for epoch in range(epochs):\n",
    "    print(f'\\nStarting epoch {epoch+1}')\n",
    "    epoch_loss = []\n",
    "    val_temp_loss = []\n",
    "\n",
    "    # Loop through training data with tqdm progress bar\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", unit=\"batch\", ncols=130)\n",
    "    for data_tuple in pbar:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # read data into dictionary\n",
    "        data_dict = {name: tensor for name, tensor in zip(selected_channels, data_tuple)}\n",
    "        \n",
    "        # prepare inputs by concatenating along channel dimension\n",
    "        if gpus == True:\n",
    "            inputs = torch.cat([data_dict[channel] for channel in input_channels], dim=1).to('cuda')\n",
    "        else:\n",
    "            inputs = torch.cat([data_dict[channel] for channel in input_channels], dim=1)\n",
    "\n",
    "        # generate prediction\n",
    "        pred_sd = model(inputs)\n",
    "\n",
    "        # Limit prediction to areas with valid data\n",
    "        if gpus == True:\n",
    "            pred_sd = torch.where(data_dict['aso_gap_map'].to('cuda') + data_dict['rtc_gap_map'].to('cuda') + data_dict['s2_gap_map'].to('cuda') == 0, pred_sd, torch.zeros_like(pred_sd).to('cuda'))\n",
    "            aso_sd = torch.where(data_dict['aso_gap_map'].to('cuda') + data_dict['rtc_gap_map'].to('cuda') + data_dict['s2_gap_map'].to('cuda')== 0, data_dict['aso_sd'].to('cuda'), torch.zeros_like(pred_sd).to('cuda'))\n",
    "        else:\n",
    "            pred_sd = torch.where(data_dict['aso_gap_map'] + data_dict['rtc_gap_map'] + data_dict['s2_gap_map'] == 0, pred_sd, torch.zeros_like(pred_sd))\n",
    "            aso_sd = torch.where(data_dict['aso_gap_map'] + data_dict['rtc_gap_map'] + data_dict['s2_gap_map'] == 0, data_dict['aso_sd'], torch.zeros_like(pred_sd))\n",
    "        \n",
    "        # Calculate loss\n",
    "        if gpus == True:\n",
    "            loss = loss_fn(pred_sd, aso_sd.to('cuda'))\n",
    "            epoch_loss.append(loss.item())\n",
    "        else:\n",
    "            loss = loss_fn(pred_sd, aso_sd)\n",
    "            epoch_loss.append(loss.item())\n",
    "            \n",
    "        # Update tqdm progress bar with batch loss\n",
    "        pbar.set_postfix({'batch loss': loss.item(), 'mean epoch loss': np.mean(epoch_loss)})\n",
    "\n",
    "\n",
    "        loss.backward()  # Propagate the gradients in backward pass\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss.append(np.mean(epoch_loss))\n",
    "    print(f'Training loss: {np.mean(epoch_loss)}')\n",
    "\n",
    "    # Run model on validation data with tqdm progress bar\n",
    "    for data_tuple in tqdm(val_loader, desc=\"Validation\", unit=\"batch\"):\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            \n",
    "            # read data into dictionary\n",
    "            data_dict = {name: tensor for name, tensor in zip(selected_channels, data_tuple)}\n",
    "            \n",
    "            # prepare inputs by concatenating along channel dimension\n",
    "            if gpus == True:\n",
    "                inputs = torch.cat([data_dict[channel] for channel in input_channels], dim=1).to('cuda')\n",
    "            else:\n",
    "                inputs = torch.cat([data_dict[channel] for channel in input_channels], dim=1)\n",
    "\n",
    "            # generate prediction\n",
    "            pred_sd = model(inputs)\n",
    "    \n",
    "            # Limit prediction to areas with valid data\n",
    "            if gpus == True:\n",
    "                pred_sd = torch.where(data_dict['aso_gap_map'].to('cuda') + data_dict['rtc_gap_map'].to('cuda') + data_dict['s2_gap_map'].to('cuda') == 0, pred_sd, torch.zeros_like(pred_sd).to('cuda'))\n",
    "                aso_sd = torch.where(data_dict['aso_gap_map'].to('cuda') + data_dict['rtc_gap_map'].to('cuda') + data_dict['s2_gap_map'].to('cuda') == 0, data_dict['aso_sd'].to('cuda'), torch.zeros_like(pred_sd).to('cuda'))\n",
    "                print('Predictions on cuda')\n",
    "            else:\n",
    "                pred_sd = torch.where(data_dict['aso_gap_map'] + data_dict['rtc_gap_map'] + data_dict['s2_gap_map'] == 0, pred_sd, torch.zeros_like(pred_sd))\n",
    "                aso_sd = torch.where(data_dict['aso_gap_map'] + data_dict['rtc_gap_map'] + data_dict['s2_gap_map'] == 0, data_dict['aso_sd'], torch.zeros_like(pred_sd))\n",
    "                print('Predictions on cpu')\n",
    "                \n",
    "            # Calculate loss\n",
    "            if gpus == True:\n",
    "                loss = loss_fn(pred_sd, aso_sd.to('cuda'))\n",
    "                val_temp_loss.append(loss.item())\n",
    "            else:\n",
    "                loss = loss_fn(pred_sd, aso_sd)\n",
    "                val_temp_loss.append(loss.item())\n",
    "                \n",
    "    val_loss.append(np.mean(val_temp_loss))\n",
    "    print(f'Validation loss: {np.mean(val_temp_loss)}')\n",
    "    \n",
    "    # # save model\n",
    "    # torch.save(model.state_dict(), f'../../../weights/{model_name}')\n",
    "\n",
    "    # # save loss \n",
    "    # with open(f'../../../loss/{model_name}_val_loss.pkl', 'wb') as f:\n",
    "    #     pickle.dump(val_loss, f)\n",
    "        \n",
    "    # with open(f'../../../loss/{model_name}_train_loss.pkl', 'wb') as f:\n",
    "    #     pickle.dump(train_loss, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337519dc-96be-4f97-af5d-ac0d255c4bd8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Plot loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1759073-9dee-411a-8cb7-a521612628d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss over all epochs\n",
    "f, ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(train_loss, label='training')\n",
    "ax.plot(val_loss, label='validation')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('MSE loss')\n",
    "ax.set_title('Loss')\n",
    "ax.legend()\n",
    "\n",
    "ax.set_xlim([0,epochs-1])\n",
    "ax.set_xticks(np.arange(0,epochs,1))\n",
    "\n",
    "\n",
    "# save figure\n",
    "#plt.savefig(f'/home/jovyan/crunchy-snow/figs/{model_name}_loss.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d78371-b064-4e72-9a68-94b91ab43b6a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Examine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2842a0-6ed9-4dda-bc59-2fd6cda18c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize model predictions\n",
    "sns.set_theme()\n",
    "num_samples = 1\n",
    "\n",
    "for i, data_tuple in enumerate(val_loader):\n",
    "    if i < num_samples:\n",
    "        # read data into dictionary\n",
    "        data_dict = {name: tensor for name, tensor in zip(selected_channels, data_tuple)}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Concatenate input feature channels, make prediction\n",
    "            inputs = torch.cat([data_dict[channel] for channel in input_channels], dim=1).to('cuda')\n",
    "            pred_sd = model(inputs)  # Generate predictions using the model\n",
    "            pred_sd = pred_sd.to('cpu')\n",
    "        \n",
    "        f, ax = plt.subplots(3, 3, figsize=(15, 15), sharex=True, sharey=True)\n",
    "        ax[0, 0].imshow(pred_sd.squeeze(), cmap='Blues', vmin=0, vmax=1, interpolation=None)\n",
    "        ax[0, 0].set_title('Predicted Snow Depth')\n",
    "        ax[0, 1].imshow(data_dict['aso_sd'].squeeze(), cmap='Blues', vmin=0, vmax=1, interpolation=None)\n",
    "        ax[0, 1].set_title('ASO Lidar Snow Depth')\n",
    "        \n",
    "        ax[0, 2].imshow(data_dict['elevation'].squeeze(), cmap='viridis', interpolation='none')\n",
    "        ax[0, 2].set_title('Copernicus DEM')\n",
    "        ax[1, 0].imshow(data_dict['fcf'].squeeze(), cmap='Greens', interpolation='none')\n",
    "        ax[1, 0].set_title('Fractional Forest Cover')\n",
    "        norm_max = np.max([data_dict['green'].max(), data_dict['red'].max(), data_dict['blue'].max()]) # there are better ways to do this\n",
    "        ax[1, 1].imshow(torch.cat((data_dict['red'].squeeze()[:, :, None]/norm_max, data_dict['green'].squeeze()[:, :, None]/norm_max, data_dict['blue'].squeeze()[:, :, None]/norm_max), 2).squeeze(), interpolation='none')\n",
    "        ax[1, 1].set_title('true color image')\n",
    "        ax[1, 2].imshow(data_dict['aso_gap_map'].squeeze() + data_dict['rtc_gap_map'].squeeze(), cmap='Purples', interpolation='none')\n",
    "        ax[1, 2].set_title('ASO and RTC Gaps')\n",
    "        ax[2, 0].imshow(data_dict['ndvi'].squeeze(), cmap='YlGn', interpolation='none')\n",
    "        ax[2, 0].set_title('NDVI')\n",
    "        ax[2, 1].imshow(data_dict['ndsi'].squeeze(), cmap='BuPu', interpolation='none')\n",
    "        ax[2, 1].set_title('NDSI')\n",
    "        ax[2, 2].imshow(data_dict['ndwi'].squeeze(), cmap='YlGnBu', interpolation='none')\n",
    "        ax[2, 2].set_title('NDWI')\n",
    "        \n",
    "        # modify plot style\n",
    "        for a in ax.flat:\n",
    "            a.set_aspect('equal')\n",
    "            a.set_xticks(np.arange(0, data_dict['aso_sd'].squeeze().shape[1], 43))\n",
    "            a.set_yticks(np.arange(0, data_dict['aso_sd'].squeeze().shape[0], 43))\n",
    "            a.grid(True, linewidth=1, alpha=0.5)\n",
    "        \n",
    "        # f.tight_layout()\n",
    "        # save figure\n",
    "        #plt.savefig(f'../../../figs/{model_name}_prediction.png', dpi=300)\n",
    "        \n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6e979b-7dac-44e1-8e78-fc8f28f1ebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize prediction error\n",
    "sns.set_theme()\n",
    "num_samples = 1\n",
    "norm_dict = crunchy_snow.dataset.norm_dict\n",
    "\n",
    "# add sample index to plot\n",
    "plot_sample = 3\n",
    "\n",
    "for i, data_tuple in enumerate(val_loader):\n",
    "    #if i < num_samples:\n",
    "    if i == 1:  \n",
    "        print(i)\n",
    "        # read data into dictionary\n",
    "        data_dict = {name: tensor for name, tensor in zip(selected_channels, data_tuple)}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Concatenate input feature channels, make prediction\n",
    "            inputs = torch.cat([data_dict[channel] for channel in input_channels], dim=1).to('cuda')\n",
    "            pred_sd = model(inputs)  # Generate predictions using the model\n",
    "            pred_sd = pred_sd.to('cpu')\n",
    "\n",
    "            # mask nodata areas\n",
    "            pred_sd = torch.where(data_dict['aso_gap_map']+data_dict['rtc_gap_map'] + data_dict['s2_gap_map'] == 0, pred_sd, torch.zeros_like(pred_sd))\n",
    "            aso_sd = torch.where(data_dict['aso_gap_map']+data_dict['rtc_gap_map'] + data_dict['s2_gap_map'] == 0, data_dict['aso_sd'], torch.zeros_like(pred_sd))\n",
    "\n",
    "            # undo normalization\n",
    "            pred_sd = crunchy_snow.dataset.undo_norm(pred_sd, crunchy_snow.dataset.norm_dict['aso_sd']).squeeze()\n",
    "            aso_sd = crunchy_snow.dataset.undo_norm(aso_sd, crunchy_snow.dataset.norm_dict['aso_sd']).squeeze()\n",
    "            \n",
    "            # mask values above 0\n",
    "            pred_sd = torch.where(pred_sd >= 0, pred_sd, torch.zeros_like(pred_sd))\n",
    "            \n",
    "            f, ax = plt.subplots(2, 2, figsize=(10,10), sharex=True, sharey=True)\n",
    "            im0 = ax[0, 0].imshow(pred_sd, cmap='Blues', vmin=0, vmax=1, interpolation='none') \n",
    "            ax[0, 0].set_title('predicted snow depth')\n",
    "            f.colorbar(im0, shrink=0.5)\n",
    "            im1 = ax[0, 1].imshow(aso_sd, cmap='Blues', vmin=0, vmax=1, interpolation='none')\n",
    "            ax[0, 1].set_title('ASO lidar snow depth')\n",
    "            f.colorbar(im1, shrink=0.5)\n",
    "\n",
    "            im2 = ax[1, 0].imshow(aso_sd-pred_sd, cmap='RdBu', vmin=-1, vmax=1, interpolation='none') \n",
    "            ax[1, 0].set_title('ASO snow depth - predicted snow depth')\n",
    "            f.colorbar(im2, shrink=0.5)\n",
    "            norm_max = np.max([data_dict['green'].max(), data_dict['red'].max(), data_dict['blue'].max()]) # there are better ways to do this\n",
    "            im3 = ax[1, 1].imshow(torch.cat((data_dict['red'].squeeze()[:, :, None]/norm_max, data_dict['green'].squeeze()[:, :, None]/norm_max, data_dict['blue'].squeeze()[:, :, None]/norm_max), 2).squeeze(), interpolation='none')\n",
    "            ax[1, 1].set_title('true color image')\n",
    "            #f.colorbar(im3, shrink=0.5)\n",
    "\n",
    "            # modify plot style\n",
    "            for a in ax.flat:\n",
    "                a.set_aspect('equal')\n",
    "                a.set_xticks(np.arange(0, data_dict['aso_sd'].squeeze().shape[1], 43))\n",
    "                a.set_yticks(np.arange(0, data_dict['aso_sd'].squeeze().shape[0], 43))\n",
    "                a.grid(True, linewidth=1, alpha=0.5)\n",
    "\n",
    "            #plt.tight_layout()\n",
    "            # save figure\n",
    "            #plt.savefig(f'../../../figs/{model_name}_prediction_err.png', dpi=300)\n",
    "    else: \n",
    "        #break\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62888d07-afd9-4901-9ba4-ac8dea9fd2ea",
   "metadata": {},
   "source": [
    "## Visualize model predictions next to baseline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b1d957-458d-4be3-9fe5-9ad3a5555a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify input channels used in baseline model\n",
    "\n",
    "input_channels_bl = [\n",
    "    'snowon_vv',\n",
    "    'snowon_vh',\n",
    "    'snowoff_vv',\n",
    "    'snowoff_vh',\n",
    "    'blue',\n",
    "    'green',\n",
    "    'red',\n",
    "    'fcf',\n",
    "    'elevation',\n",
    "    'ndvi',\n",
    "    'ndsi',\n",
    "    'ndwi',\n",
    "    'snowon_cr',\n",
    "    'snowoff_cr'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c99a3cb-7602-4aa4-813e-1e304bbefbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load previous model\n",
    "model_bl = crunchy_snow.models.ResDepth(n_input_channels=len(input_channels_bl))\n",
    "\n",
    "model_baseline = 'quinn_ResDepth_v3'\n",
    "# GPU:\n",
    "if gpus == True:\n",
    "    model_bl.load_state_dict(torch.load('/home/jovyan/crunchy-snow/weights/'+model_baseline))\n",
    "    model_bl.to('cuda');    # to gpu memory from cpu \n",
    "    print('baseline model on cuda')\n",
    "    \n",
    "# CPU:\n",
    "else:\n",
    "    model_bl.load_state_dict(torch.load('/home/jovyan/crunchy-snow/weights/'+model_baseline, map_location=torch.device('cpu')))\n",
    "    print('baseline model on cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bf24fe-4eaa-4ec2-b416-731c15825196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize predictions from baseline and new model\n",
    "\n",
    "# ----------------------------\n",
    "# specify sample index to plot\n",
    "plot_sample = 10\n",
    "#\n",
    "# ----------------------------\n",
    "\n",
    "\n",
    "sns.set_theme()\n",
    "norm_dict = crunchy_snow.dataset.norm_dict\n",
    "\n",
    "\n",
    "for i, data_tuple in enumerate(val_loader):\n",
    "    print(i)\n",
    "    if i == plot_sample:\n",
    "        print(i)\n",
    "        # read data into dictionary\n",
    "        data_dict = {name: tensor for name, tensor in zip(selected_channels, data_tuple)}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Concatenate input feature channels, make prediction\n",
    "\n",
    "            if gpus == True:\n",
    "                # baseline model:\n",
    "                inputs_bl = torch.cat([data_dict[channel] for channel in input_channels_bl], dim=1).to('cuda')\n",
    "                pred_sd_bl = model_bl(inputs_bl)  # Generate predictions using the model\n",
    "                pred_sd_bl = pred_sd_bl.to('cpu')\n",
    "\n",
    "                # new test model:\n",
    "                inputs = torch.cat([data_dict[channel] for channel in input_channels], dim=1).to('cuda')\n",
    "                pred_sd = model(inputs)  # Generate predictions using the model\n",
    "                pred_sd = pred_sd.to('cpu')\n",
    "\n",
    "                # lidar data:\n",
    "                aso_sd = aso_sd.to('cpu')\n",
    "\n",
    "                # elevation:\n",
    "                elev = data_dict['elevation'].to('cpu')\n",
    "            \n",
    "            else:\n",
    "                # baseline model:\n",
    "                inputs_bl = torch.cat([data_dict[channel] for channel in input_channels_bl], dim=1)\n",
    "                pred_sd_bl = model_bl(inputs_bl)  # Generate predictions using the model\n",
    "\n",
    "                # new test model:\n",
    "                inputs = torch.cat([data_dict[channel] for channel in input_channels], dim=1)\n",
    "                pred_sd = model(inputs)  # Generate predictions using the model\n",
    "            \n",
    "        f, axs = plt.subplots(3, 2, figsize=(10, 18))#, sharex=True, sharey=True)\n",
    "        f.patch.set_facecolor('white')\n",
    "\n",
    "        ax = axs.flatten()\n",
    "\n",
    "        # modify plot style\n",
    "        for a in ax:\n",
    "            a.set_aspect('equal')\n",
    "            a.set_xticks(np.arange(0, data_dict['aso_sd'].squeeze().shape[1], 43))\n",
    "            a.set_yticks(np.arange(0, data_dict['aso_sd'].squeeze().shape[0], 43))\n",
    "            a.grid(True, linewidth=1, alpha=0.5)\n",
    "\n",
    "        # undo normalization to calculate max\n",
    "        pred_sd_unnorm = crunchy_snow.dataset.undo_norm(pred_sd, crunchy_snow.dataset.norm_dict['aso_sd']).squeeze()\n",
    "        aso_sd_unnorm = crunchy_snow.dataset.undo_norm(aso_sd, crunchy_snow.dataset.norm_dict['aso_sd']).squeeze()\n",
    "        pred_sd_bl_unnorm = crunchy_snow.dataset.undo_norm(pred_sd_bl, crunchy_snow.dataset.norm_dict['aso_sd']).squeeze()\n",
    "        \n",
    "        elev_unnorm = crunchy_snow.dataset.undo_norm(elev, crunchy_snow.dataset.norm_dict['elevation']).squeeze()\n",
    "        \n",
    "        # calculate max:\n",
    "        pred_sd_max = np.round(float(pred_sd_unnorm.max()),1)\n",
    "        aso_sd_max = np.round(float(aso_sd_unnorm.max()),1)\n",
    "        pred_sd_bl_max = np.round(float(pred_sd_bl_unnorm.max()),1)\n",
    "        elev_max = np.round(float(elev_unnorm.max()),1)\n",
    "\n",
    "        pred_bl_diff_max = np.round(float(np.abs(pred_sd_bl_unnorm-aso_sd_unnorm).max()),1)\n",
    "        pred_diff_max = np.round(float(np.abs(pred_sd_unnorm-aso_sd_unnorm).max()),1)\n",
    "\n",
    "        ####### Plots:\n",
    "        \n",
    "        # Baseline model:\n",
    "        im0 = ax[0].imshow(pred_sd_bl.squeeze(), cmap='Blues', vmin=0, vmax=0.4, interpolation=None)\n",
    "        ax[0].set_title(r'Predicted Snow Depth: $\\it{Baseline\\ Model}$', fontsize=12,y=1.02,loc='center', horizontalalignment='center')\n",
    "        ax[0].text(0.87, -0.05, 'Max Depth:\\n'+str(pred_sd_bl_max)+' m', fontsize=7, fontweight='medium', ha='center', va='center', transform=ax[0].transAxes, color='gray', zorder=12) \n",
    "        ax[0].text(1.12, 0.9, 'LR: '+str(0.0003), fontsize=7, fontweight='medium', ha='center', va='center', transform=ax[0].transAxes, color='gray', zorder=12) \n",
    "        ax[0].text(1.12, 0.85, 'Epochs: '+str(50), fontsize=7, fontweight='medium', ha='center', va='center', transform=ax[0].transAxes, color='gray', zorder=12) \n",
    "        ax[0].text(1.12, 0.8, 'Batch: '+str(16), fontsize=7, fontweight='medium', ha='center', va='center', transform=ax[0].transAxes, color='gray', zorder=12) \n",
    "\n",
    "        \n",
    "        # Add axis for predicted snow depth colorbar\n",
    "        cax0 = ax[0].inset_axes([0.1, -0.15, 0.8, 0.04])\n",
    "        cb0 = f.colorbar(im0, extend='max', orientation=\"horizontal\",pad=0.1,fraction=0.037,shrink=0.9,aspect=35,ax=ax[0], cax=cax0)\n",
    "        cb0.outline.set_visible(True)\n",
    "        cb0.outline.set_linewidth(0.5)\n",
    "        cb0.outline.set_edgecolor('black')\n",
    "\n",
    "        # ----\n",
    "        \n",
    "        # Difference -- baseline - observations:\n",
    "        im1 = ax[1].imshow((pred_sd_bl - aso_sd).squeeze(), cmap='RdBu_r', vmin=-0.4, vmax=0.4, interpolation='none') \n",
    "        ax[1].set_title(r'Baseline Snow Depth $-$ ASO Snow Depth', fontsize=12,y=1.02,loc='center', horizontalalignment='center')\n",
    "        ax[1].text(0.87, -0.05, 'Max Error Magnitude:\\n'+str(pred_bl_diff_max)+' m', fontsize=7, fontweight='medium', ha='center', va='center', transform=ax[1].transAxes, color='gray', zorder=12) \n",
    "\n",
    "\n",
    "        # Add axis for differences colorbar\n",
    "        cax1 = ax[1].inset_axes([0.1, -0.15, 0.8, 0.04])\n",
    "        cb1 = f.colorbar(im1, extend='both', orientation=\"horizontal\",pad=0.1,fraction=0.037,shrink=0.9,aspect=35,ax=ax[1], cax=cax1)\n",
    "        cb1.outline.set_visible(True)\n",
    "        cb1.outline.set_linewidth(0.5)\n",
    "        cb1.outline.set_edgecolor('black')    \n",
    "        \n",
    "        # ----\n",
    "        \n",
    "        # New model:\n",
    "        im2 = ax[2].imshow(pred_sd.squeeze(), cmap='Blues', vmin=0, vmax=0.4, interpolation=None)\n",
    "        ax[2].set_title(r'Predicted Snow Depth: $\\it{Test\\ Model}$', fontsize=12,y=1.02,loc='center', horizontalalignment='center')\n",
    "        ax[2].text(0.87, -0.05, 'Max Depth:\\n'+str(pred_sd_max)+' m', fontsize=7, fontweight='medium', ha='center', va='center', transform=ax[2].transAxes, color='gray', zorder=12) \n",
    "        ax[2].text(1.12, 0.95, '# Samples: '+str(n_imgs), fontsize=7, fontweight='medium', ha='center', va='center', transform=ax[2].transAxes, color='gray', zorder=12) \n",
    "        ax[2].text(1.12, 0.9, 'LR: '+str(learning_rate), fontsize=7, fontweight='medium', ha='center', va='center', transform=ax[2].transAxes, color='gray', zorder=12) \n",
    "        ax[2].text(1.12, 0.85, 'Epochs: '+str(epochs), fontsize=7, fontweight='medium', ha='center', va='center', transform=ax[2].transAxes, color='gray', zorder=12) \n",
    "        ax[2].text(1.12, 0.8, 'Batch: '+str(train_batch), fontsize=7, fontweight='medium', ha='center', va='center', transform=ax[2].transAxes, color='gray', zorder=12) \n",
    "\n",
    "        \n",
    "        # Add axis for predicted snow depth colorbar\n",
    "        cax2 = ax[2].inset_axes([0.1, -0.15, 0.8, 0.04])\n",
    "        cb2 = f.colorbar(im2, extend='max', orientation=\"horizontal\",pad=0.1,fraction=0.037,shrink=0.9,aspect=35,ax=ax[2], cax=cax2)\n",
    "        cb2.outline.set_visible(True)\n",
    "        cb2.outline.set_linewidth(0.5)\n",
    "        cb2.outline.set_edgecolor('black')\n",
    "        \n",
    "        # ----\n",
    "        \n",
    "        # Difference -- new model - observations:\n",
    "        im3 = ax[3].imshow((pred_sd - aso_sd).squeeze(), cmap='RdBu_r', vmin=-0.4, vmax=0.4, interpolation='none') \n",
    "        ax[3].set_title(r'Test Snow Depth $-$ ASO Snow Depth', fontsize=12,y=1.02,loc='center', horizontalalignment='center')\n",
    "        ax[3].text(0.87, -0.05, 'Max Error Magnitude:\\n'+str(pred_diff_max)+' m', fontsize=7, fontweight='medium', ha='center', va='center', transform=ax[3].transAxes, color='gray', zorder=12) \n",
    "\n",
    "        \n",
    "        # Add axis for differences colorbar\n",
    "        cax3 = ax[3].inset_axes([0.1, -0.15, 0.8, 0.04])\n",
    "        cb3 = f.colorbar(im3, extend='both', orientation=\"horizontal\",pad=0.1,fraction=0.037,shrink=0.9,aspect=35,ax=ax[3], cax=cax3)\n",
    "        cb3.outline.set_visible(True)\n",
    "        cb3.outline.set_linewidth(0.5)\n",
    "        cb3.outline.set_edgecolor('black')   \n",
    "        \n",
    "        # ----\n",
    "        \n",
    "        # Lidar snow depth:\n",
    "        im4 = ax[4].imshow(aso_sd.squeeze(), cmap='Blues', vmin=0, vmax=0.4, interpolation=None)\n",
    "        ax[4].set_title('ASO Lidar Snow Depth',fontsize=12,y=1.02,loc='center', horizontalalignment='center')\n",
    "        ax[4].text(0.87, -0.05, 'Max Depth:\\n'+str(aso_sd_max)+' m', fontsize=7, fontweight='medium', ha='center', va='center', transform=ax[4].transAxes, color='gray', zorder=12) \n",
    "\n",
    "\n",
    "        # Add axis for observed snow depth colorbar\n",
    "        cax4 = ax[4].inset_axes([0.1, -0.15, 0.8, 0.04])\n",
    "        cb4 = f.colorbar(im4, extend='max', orientation=\"horizontal\",pad=0.1,fraction=0.037,shrink=0.9,aspect=35,ax=ax[4], cax=cax4)\n",
    "        cb4.outline.set_visible(True)\n",
    "        cb4.outline.set_linewidth(0.5)\n",
    "        cb4.outline.set_edgecolor('black')\n",
    "\n",
    "        # ----\n",
    "        \n",
    "        # Elevation:\n",
    "        im5 = ax[5].imshow(data_dict['elevation'].squeeze(), cmap='gist_earth', vmin=0, vmax=0.7, interpolation=None)\n",
    "        ax[5].set_title('Copernicus DEM',fontsize=12,y=1.02,loc='center', horizontalalignment='center')\n",
    "        ax[5].text(0.87, -0.05, 'Max Elevation:\\n'+str(elev_max)+' m', fontsize=7, fontweight='medium', ha='center', va='center', transform=ax[5].transAxes, color='gray', zorder=12) \n",
    "\n",
    "\n",
    "        # Add axis for elevation colorbar\n",
    "        cax5 = ax[5].inset_axes([0.1, -0.15, 0.8, 0.04])\n",
    "        cb5 = f.colorbar(im5, extend='max', orientation=\"horizontal\",pad=0.1,fraction=0.037,shrink=0.9,aspect=35,ax=ax[5], cax=cax5)\n",
    "        cb5.outline.set_visible(True)\n",
    "        cb5.outline.set_linewidth(0.5)\n",
    "        cb5.outline.set_edgecolor('black')\n",
    "        \n",
    "        # Clean up subplots / layout.\n",
    "        f.subplots_adjust(bottom=0.1, top=0.9, left=0.1, right=0.9, wspace=0.45, hspace=0.4)\n",
    "\n",
    "        plt.savefig(f'/home/jovyan/crunchy-snow/figs/snowdepth_{model_baseline}_{model_name}_sample{plot_sample}_{n_imgs}imgs_{epochs}epochs.png', dpi=300)\n",
    "\n",
    "\n",
    "    else:\n",
    "        #break\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f16c9dd-bf74-4afa-b170-4e6ba7edfe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RMSE and max error for each sample\n",
    "\n",
    "nsample = []\n",
    "rmse_pred_sd = []\n",
    "max_err_pred_sd = []\n",
    "\n",
    "rmse_pred_sd_bl = []\n",
    "max_err_pred_sd_bl = []\n",
    "\n",
    "for i, data_tuple in enumerate(val_loader):\n",
    "    nsample.append(i)\n",
    "\n",
    "    # read data into dictionary\n",
    "    data_dict = {name: tensor for name, tensor in zip(selected_channels, data_tuple)}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Concatenate input feature channels, make prediction\n",
    "\n",
    "        if gpus == True:\n",
    "            \n",
    "            # baseline model:\n",
    "            inputs_bl = torch.cat([data_dict[channel] for channel in input_channels_bl], dim=1).to('cuda')\n",
    "            pred_sd_bl = model_bl(inputs_bl)  # Generate predictions using the model\n",
    "            pred_sd_bl = pred_sd_bl.to('cpu')\n",
    "\n",
    "            # new test model:\n",
    "            inputs = torch.cat([data_dict[channel] for channel in input_channels], dim=1).to('cuda')\n",
    "            pred_sd = model(inputs)  # Generate predictions using the model\n",
    "            pred_sd = pred_sd.to('cpu')\n",
    "\n",
    "            # lidar data:\n",
    "            aso_sd = aso_sd.to('cpu')\n",
    "        \n",
    "        else:\n",
    "            # baseline model:\n",
    "            inputs_bl = torch.cat([data_dict[channel] for channel in input_channels_bl], dim=1)\n",
    "            pred_sd_bl = model_bl(inputs_bl)  # Generate predictions using the model\n",
    "\n",
    "            # new test model:\n",
    "            inputs = torch.cat([data_dict[channel] for channel in input_channels], dim=1)\n",
    "            pred_sd = model(inputs)  # Generate predictions using the model\n",
    "\n",
    "        # undo normalization to calculate max\n",
    "        pred_sd_unnorm = crunchy_snow.dataset.undo_norm(pred_sd, crunchy_snow.dataset.norm_dict['aso_sd']).squeeze()\n",
    "        aso_sd_unnorm = crunchy_snow.dataset.undo_norm(aso_sd, crunchy_snow.dataset.norm_dict['aso_sd']).squeeze()\n",
    "        pred_sd_bl_unnorm = crunchy_snow.dataset.undo_norm(pred_sd_bl, crunchy_snow.dataset.norm_dict['aso_sd']).squeeze()\n",
    "\n",
    "        pred_sd_rmse = skmetrics.mean_squared_error(aso_sd_unnorm, pred_sd_unnorm, squared=False)   \n",
    "        rmse_pred_sd.append(pred_sd_rmse)\n",
    "\n",
    "        pred_sd_maxerr = skmetrics.max_error(aso_sd_unnorm.flatten(), pred_sd_unnorm.flatten())\n",
    "        max_err_pred_sd.append(pred_sd_maxerr)\n",
    "\n",
    "        pred_sd_bl_rmse = skmetrics.mean_squared_error(aso_sd_unnorm, pred_sd_bl_unnorm, squared=False)   \n",
    "        rmse_pred_sd_bl.append(pred_sd_bl_rmse)\n",
    "\n",
    "        pred_sd_bl_maxerr = skmetrics.max_error(aso_sd_unnorm.flatten(), pred_sd_bl_unnorm.flatten())\n",
    "        max_err_pred_sd_bl.append(pred_sd_bl_maxerr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91e0ce5-69af-4137-a677-058c5baafe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot error for each sample\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "f, axs = plt.subplots(2,1,figsize=(10,7))\n",
    "\n",
    "ax = axs.flatten()\n",
    "\n",
    "# RMSE for models\n",
    "ax[0].plot(rmse_pred_sd_bl, color='xkcd:velvet', label='Baseline Model')\n",
    "ax[0].plot(rmse_pred_sd, color='xkcd:blue green', label='Test Model')\n",
    "\n",
    "ax[0].set_xlim([0,len(rmse_pred_sd)-1])\n",
    "ax[0].set_xticks(np.arange(0,len(rmse_pred_sd_bl),1))\n",
    "ax[0].set_ylim([0,max(np.maximum(rmse_pred_sd_bl,rmse_pred_sd))+0.2])\n",
    "\n",
    "ax[0].set_title(r'Snow Depth RMSE Per Sample', fontsize=12,y=1.02,loc='left', horizontalalignment='left')\n",
    "ax[0].legend()\n",
    "\n",
    "# Max errors for models\n",
    "ax[1].plot(max_err_pred_sd_bl, color='xkcd:velvet', label='Baseline Model')\n",
    "ax[1].plot(max_err_pred_sd, color='xkcd:blue green', label='Test Model')\n",
    "\n",
    "ax[1].set_xlim([0,len(max_err_pred_sd_bl)-1])\n",
    "ax[1].set_xticks(np.arange(0,len(max_err_pred_sd_bl),1))\n",
    "ax[1].set_ylim([int(min(np.minimum(max_err_pred_sd_bl,max_err_pred_sd))-0.2),max(np.maximum(max_err_pred_sd_bl,max_err_pred_sd))+0.2])\n",
    "\n",
    "ax[1].set_title(r'Snow Depth Max Error Per Sample', fontsize=12,y=1.02,loc='left', horizontalalignment='left')\n",
    "ax[1].legend()\n",
    "\n",
    "# Clean up subplots / layout.\n",
    "f.subplots_adjust(bottom=0.05, top=0.95, left=0.1, right=0.9, wspace=0.45, hspace=0.4)\n",
    "\n",
    "\n",
    "# save figure\n",
    "plt.savefig(f'/home/jovyan/crunchy-snow/figs/errorpersample_{model_baseline}_{model_name}_{n_imgs}imgs_{epochs}eps.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc991326-4988-4085-860e-26e0ab08efe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
