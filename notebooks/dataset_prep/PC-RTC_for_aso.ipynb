{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f5064e2-5ec3-4be7-9041-f825ee38c249",
   "metadata": {},
   "source": [
    "# Download Sentinel-1 RTC for each ASO raster\n",
    "Given an ASO raster, find and download 1) the most proximate in time S1 RTC product 2) a \"snow-off\" RTC product from the preceeding summer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54fdc55-62d9-4c67-bb24-c213da49ed3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# based on exmaples from\n",
    "# https://planetarycomputer.microsoft.com/docs/tutorials/cloudless-mosaic-sentinel2/\n",
    "# https://planetarycomputer.microsoft.com/dataset/sentinel-2-l2a#Example-Notebook\n",
    "from pystac.extensions.eo import EOExtension as eo\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "import glob\n",
    "import rioxarray as rxr\n",
    "import re, os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from shapely.geometry import box\n",
    "import odc.stac\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import rasterio as rio\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3045b36-213a-493d-9e95-845355ac1423",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/tmp/ipykernel_28221/1174516660.py:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  time = pd.to_datetime(re.search(\"(\\d{4}\\d{2}\\d{2})\", aso_raster_fn).group())\n"
     ]
    }
   ],
   "source": [
    "def rtc_for_aso_snowon(aso_raster_fn, dataset_path):\n",
    "    time = pd.to_datetime(re.search(\"(\\d{4}\\d{2}\\d{2})\", aso_raster_fn).group())\n",
    "    week_before = (time - datetime.timedelta(weeks=2)).strftime('%Y-%m-%d')\n",
    "    week_after = (time + datetime.timedelta(weeks=2)).strftime('%Y-%m-%d')\n",
    "    time_of_interest = f'{week_before}/{week_after}'\n",
    "    \n",
    "    aso_raster = rxr.open_rasterio(aso_raster_fn).squeeze()\n",
    "    aso_raster = aso_raster.where(aso_raster>=0, drop=True)\n",
    "    bounds_latlon = box(*aso_raster.rio.transform_bounds(\"EPSG:4326\"))\n",
    "    \n",
    "    catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace)\n",
    "\n",
    "    search = catalog.search(\n",
    "        collections=[\"sentinel-1-rtc\"],\n",
    "        intersects=bounds_latlon,\n",
    "        datetime=time_of_interest)\n",
    "    \n",
    "    # Check how many items were returned\n",
    "    items = search.item_collection()\n",
    "    \n",
    "    rtc_stac = odc.stac.load(items,chunks={\"x\": 2048, \"y\": 2048},resolution=50, groupby='sat:absolute_orbit')\n",
    "    print(f\"Returned {len(rtc_stac.time)} acquisitions\")\n",
    "    rtc_stac_clipped = rtc_stac.rio.clip_box(*bounds_latlon.bounds,crs=\"EPSG:4326\")\n",
    "    \n",
    "    rel_orbits = [scene.properties['sat:relative_orbit'] for scene in items.items]\n",
    "    ac_times = [scene.properties['datetime'] for scene in items.items]\n",
    "    ac_times = [np.datetime64(item) for item in ac_times]\n",
    "    \n",
    "    # clip to ASO extent\n",
    "    rtc_stac_clipped = rtc_stac_clipped.rio.reproject_match(aso_raster, resampling=rio.enums.Resampling.bilinear)\n",
    "\n",
    "    # limit to morning acquisitions\n",
    "    rtc_ds = rtc_stac_clipped.where(rtc_stac_clipped.time.dt.hour > 11, drop=True)\n",
    "    if 'vv' not in list(rtc_ds.keys()) or 'vh' not in list(rtc_ds.keys()):\n",
    "        print('missing polarization')\n",
    "        return None\n",
    "    \n",
    "    if len(rtc_ds.time) == 0:\n",
    "        print('no morning acquisitions')\n",
    "        return None\n",
    "        \n",
    "    # calculate percent vh coverage of each acquisition\n",
    "    perc_cover = (rtc_ds.vh.where(aso_raster >= 0) > 0).sum(dim=['x', 'y'])/(rtc_ds.vh.where(aso_raster >= 0) >= -1000000000).sum(dim=['x', 'y'])\n",
    "    \n",
    "    # if multiple with full coverage, grab nearest in time with full coverage\n",
    "    if perc_cover.values.tolist().count(1) > 1:\n",
    "        print('total snow-on coverage available')\n",
    "        rtc_ds = rtc_ds.where(perc_cover == 1, drop=True).sortby('time')\n",
    "        rtc_ds = rtc_ds.sel(time=time, method='nearest')\n",
    "\n",
    "    # exit if no rasters have good vh coverage\n",
    "    elif perc_cover.max() < 0.01:\n",
    "        print('max vh coverage is < 1%--recommend skipping ASO raster')\n",
    "        return None\n",
    "\n",
    "    # otherwise, grab max coverage \n",
    "    else:\n",
    "        if perc_cover.max() == 1:\n",
    "            print('total snow-on coverage available')\n",
    "        else: \n",
    "            print(f'{perc_cover.max().item()} snow-on coverage')\n",
    "        rtc_ds = rtc_ds.sel(time=perc_cover.idxmax())\n",
    "\n",
    "    # get relative orbit of scene\n",
    "    rel_orbit = rel_orbits[ac_times.index(rtc_ds.time)]\n",
    "    \n",
    "    # mask negative areas\n",
    "    rtc_ds = rtc_ds.where(rtc_ds.vh > 0)\n",
    "    rtc_ds = rtc_ds.where(rtc_ds.vv > 0)\n",
    "    \n",
    "    os.makedirs(os.path.join(dataset_path, 'S1_rtc'), exist_ok=True)\n",
    "    rtc_ds.to_netcdf(os.path.join(dataset_path, 'S1_rtc', f'S1_snow-on_{rtc_ds.time.dt.strftime(\"%Y%m%d\").item()}_for_{aso_raster_fn.replace(\"\\\\\",\"/\").split(\"/\")[-1][:-4]}.nc'))\n",
    "    \n",
    "    return rel_orbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae24ec3b-ff09-4a46-81e0-befb4c7efbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/tmp/ipykernel_28221/1462774032.py:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  year = pd.to_datetime(re.search(\"(\\d{4}\\d{2}\\d{2})\", aso_raster_fn).group()).year\n"
     ]
    }
   ],
   "source": [
    "def rtc_for_aso_snowoff(aso_raster_fn, rel_orbit, dataset_path):\n",
    "    year = pd.to_datetime(re.search(\"(\\d{4}\\d{2}\\d{2})\", aso_raster_fn).group()).year\n",
    "    time = pd.to_datetime(f'{year-1}0910')\n",
    "    week_before = (time - datetime.timedelta(weeks=2)).strftime('%Y-%m-%d')\n",
    "    week_after = (time + datetime.timedelta(weeks=2)).strftime('%Y-%m-%d')\n",
    "    time_of_interest = f'{week_before}/{week_after}'\n",
    "\n",
    "    aso_raster = rxr.open_rasterio(aso_raster_fn).squeeze()\n",
    "    aso_raster = aso_raster.where(aso_raster>=0, drop=True)\n",
    "    bounds_latlon = box(*aso_raster.rio.transform_bounds(\"EPSG:4326\"))\n",
    "\n",
    "    catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace)\n",
    "\n",
    "    search = catalog.search(\n",
    "        collections=[\"sentinel-1-rtc\"],\n",
    "        intersects=bounds_latlon,\n",
    "        datetime=time_of_interest)\n",
    "\n",
    "    # Check how many items were returned\n",
    "    items = search.item_collection()\n",
    "\n",
    "    rel_orbits = [scene.properties['sat:relative_orbit'] for scene in items.items]\n",
    "    ac_times = [scene.properties['datetime'] for scene in items.items]\n",
    "    ac_times = [np.datetime64(item) for item in ac_times]\n",
    "\n",
    "    rtc_stac = odc.stac.load(items,chunks={\"x\": 2048, \"y\": 2048},resolution=50, groupby='sat:absolute_orbit')\n",
    "    print(f\"Returned {len(rtc_stac.time)} acquisitions\")\n",
    "    rtc_stac_clipped = rtc_stac.rio.clip_box(*bounds_latlon.bounds,crs=\"EPSG:4326\")\n",
    "\n",
    "    orbit_dict = {}\n",
    "    for i, orbit in enumerate(rel_orbits):\n",
    "        if orbit not in orbit_dict.keys():\n",
    "            orbit_dict[orbit] = [ac_times[i]]\n",
    "        else:\n",
    "            orbit_dict[orbit].append(ac_times[i])\n",
    "\n",
    "    if rel_orbit not in orbit_dict.keys():\n",
    "        print('no acquisitons from same orbit, skipping')\n",
    "        return\n",
    "\n",
    "    rtc_stac_clipped = rtc_stac_clipped.where(rtc_stac_clipped.time.isin(orbit_dict[rel_orbit]), drop=True)\n",
    "\n",
    "    # clip to ASO extent\n",
    "    rtc_stac_clipped = rtc_stac_clipped.rio.reproject_match(aso_raster, resampling=rio.enums.Resampling.bilinear)\n",
    "\n",
    "    # limit to morning acquisitions\n",
    "    rtc_ds = rtc_stac_clipped.where(rtc_stac_clipped.time.dt.hour > 11, drop=True)\n",
    "    if 'vv' not in list(rtc_ds.keys()) or 'vh' not in list(rtc_ds.keys()):\n",
    "            print('missing polarization, skipping')\n",
    "            return\n",
    "    \n",
    "    if len(rtc_ds.time) == 0:\n",
    "        print('no morning acquisitions')\n",
    "        return None\n",
    "\n",
    "    # calculate percent vh coverage of each acquisition\n",
    "    perc_cover = (rtc_ds.vh.where(aso_raster >= 0) > 0).sum(dim=['x', 'y'])/(rtc_ds.vh.where(aso_raster >= 0) >= -1000000000).sum(dim=['x', 'y'])\n",
    "\n",
    "    # if multiple with full coverage, grab nearest in time with full coverage\n",
    "    if perc_cover.values.tolist().count(1) > 1:\n",
    "        print('total snow-off coverage available')\n",
    "        rtc_ds = rtc_ds.where(perc_cover == 1, drop=True).sortby('time')\n",
    "        rtc_ds = rtc_ds.sel(time=time, method='nearest')\n",
    "\n",
    "    # exit if no rasters have good vh coverage\n",
    "    elif perc_cover.max() < 0.01:\n",
    "        print('max vh coverage is < 1%--recommend skipping ASO raster')\n",
    "        return\n",
    "\n",
    "    # otherwise, grab max coverage \n",
    "    else:\n",
    "        if perc_cover.max() == 1:\n",
    "            print('total snow-off coverage available')\n",
    "        else: \n",
    "            print(f'{perc_cover.max().item()} snow-off coverage')\n",
    "        rtc_ds = rtc_ds.sel(time=perc_cover.idxmax())\n",
    "    \n",
    "    # mask negative areas\n",
    "    rtc_ds = rtc_ds.where(rtc_ds.vh > 0)\n",
    "    rtc_ds = rtc_ds.where(rtc_ds.vv > 0)\n",
    "    \n",
    "    os.makedirs(os.path.join(dataset_path, 'S1_rtc'), exist_ok=True)\n",
    "    rtc_ds.to_netcdf(os.path.join(dataset_path, 'S1_rtc', f'S1_snow-off_{rtc_ds.time.dt.strftime(\"%Y%m%d\").item()}_for_{aso_raster_fn.replace(\"\\\\\",\"/\").split(\"/\")[-1][:-4]}.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6e99807-8fd3-4bdd-aa2a-44beed78015d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rtc_for_aso_all(dir_path, dataset_path):\n",
    "    raster_paths = glob.glob(os.path.join(dir_path, 'utm11n', 'ASO_50M_SD*.tif'))\n",
    "    for i, path in enumerate(raster_paths):\n",
    "        print(f'----\\nworking on {path.replace(\"\\\\\",\"/\").split(\"/\")[-1]}, {i+1}/{len(raster_paths)}\\n----')\n",
    "        \n",
    "        try:\n",
    "            relative_orbit = rtc_for_aso_snowon(path, dataset_path)\n",
    "            if relative_orbit == None:\n",
    "                continue\n",
    "            rtc_for_aso_snowoff(path, relative_orbit, dataset_path)\n",
    "        except Exception as exc:\n",
    "            print(traceback.format_exc())\n",
    "            print(exc)\n",
    "            print('encountered error, skipping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57953403-83c7-49f9-9230-1006abc3d961",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "working on ASO_50M_SD_USCALB_20170815_clean.tif, 1/159\n",
      "----\n",
      "Returned 7 acquisitions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28221/1174516660.py:29: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  ac_times = [np.datetime64(item) for item in ac_times]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total snow-on coverage available\n",
      "Returned 6 acquisitions\n",
      "total snow-off coverage available\n",
      "----\n",
      "working on ASO_50M_SD_Carson_20220311_clean.tif, 2/159\n",
      "----\n",
      "Returned 7 acquisitions\n",
      "total snow-on coverage available\n",
      "Returned 19 acquisitions\n",
      "total snow-off coverage available\n",
      "----\n",
      "working on ASO_50M_SD_USCAMB_20190703_clean.tif, 3/159\n",
      "----\n",
      "Returned 15 acquisitions\n",
      "total snow-on coverage available\n",
      "Returned 10 acquisitions\n",
      "total snow-off coverage available\n",
      "----\n",
      "working on ASO_50M_SD_Merced_20230515_clean.tif, 4/159\n",
      "----\n",
      "Returned 10 acquisitions\n",
      "total snow-on coverage available\n",
      "Returned 10 acquisitions\n",
      "total snow-off coverage available\n",
      "----\n",
      "working on ASO_50M_SD_USCARC_20170717_clean.tif, 5/159\n",
      "----\n",
      "Returned 6 acquisitions\n",
      "total snow-on coverage available\n",
      "Returned 6 acquisitions\n",
      "0.5224608681238012 snow-off coverage\n",
      "----\n",
      "working on ASO_50M_SD_Merced_20220513_clean.tif, 6/159\n",
      "----\n",
      "Returned 10 acquisitions\n",
      "total snow-on coverage available\n",
      "Returned 19 acquisitions\n",
      "total snow-off coverage available\n",
      "----\n",
      "working on ASO_50M_SD_USCATB_20160426_clean.tif, 7/159\n",
      "----\n",
      "Returned 8 acquisitions\n",
      "0.4939272428479717 snow-on coverage\n",
      "Returned 4 acquisitions\n",
      "missing polarization, skipping\n",
      "----\n",
      "working on ASO_50M_SD_USCAKN_20180426_clean.tif, 8/159\n",
      "----\n",
      "Returned 5 acquisitions\n",
      "total snow-on coverage available\n",
      "Returned 7 acquisitions\n",
      "total snow-off coverage available\n",
      "----\n",
      "working on ASO_50M_SD_Tuolumne_20230316_clean.tif, 9/159\n",
      "----\n",
      "Returned 10 acquisitions\n",
      "total snow-on coverage available\n",
      "Returned 10 acquisitions\n",
      "total snow-off coverage available\n",
      "----\n",
      "working on ASO_50M_SD_USCAMB_20190329_clean.tif, 10/159\n",
      "----\n",
      "Returned 14 acquisitions\n",
      "total snow-on coverage available\n",
      "Returned 10 acquisitions\n",
      "total snow-off coverage available\n",
      "----\n",
      "working on ASO_50M_SD_Carson_20230607_clean.tif, 11/159\n",
      "----\n",
      "Returned 10 acquisitions\n",
      "total snow-on coverage available\n",
      "Returned 10 acquisitions\n",
      "total snow-off coverage available\n",
      "----\n",
      "working on ASO_50M_SD_USCAJW_20190605_clean.tif, 12/159\n",
      "----\n",
      "Returned 14 acquisitions\n",
      "total snow-on coverage available\n",
      "Returned 10 acquisitions\n",
      "total snow-off coverage available\n",
      "----\n",
      "working on ASO_50M_SD_SanJoaquin_20210503_clean.tif, 13/159\n",
      "----\n",
      "Returned 17 acquisitions\n",
      "total snow-on coverage available\n",
      "Returned 18 acquisitions\n",
      "total snow-off coverage available\n",
      "----\n",
      "working on ASO_50M_SD_Kern_20230204_clean.tif, 14/159\n",
      "----\n",
      "Returned 10 acquisitions\n",
      "total snow-on coverage available\n",
      "Returned 10 acquisitions\n",
      "total snow-off coverage available\n",
      "----\n",
      "working on ASO_50M_SD_SanJoaquin_20200608_clean.tif, 15/159\n",
      "----\n",
      "Returned 20 acquisitions\n"
     ]
    }
   ],
   "source": [
    "dir_path = r\"/home/ayushg12/ML_GEO2024_ayushg12/mlgeo-2024-deep-snow/final_data/ASO_50m_SD_cleaned\"\n",
    "dataset_path = r\"/home/ayushg12/ML_GEO2024_ayushg12/mlgeo-2024-deep-snow/final_data\"\n",
    "test = rtc_for_aso_all(dir_path, dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df442f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-snow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
