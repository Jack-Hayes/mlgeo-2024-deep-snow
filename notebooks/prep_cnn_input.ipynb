{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import xarray as xr\n",
    "import rasterio as rio\n",
    "import rioxarray\n",
    "import math\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import deep_snow.models\n",
    "from deep_snow.dataset import norm_dict\n",
    "from deep_snow.utils import calc_norm, undo_norm, calc_dowy\n",
    "from tqdm import tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = \"/mnt/c/Users/JackE/uw/courses/aut24/ml_geo/final_data/subsets_v4/train\"\n",
    "files = glob(f\"{parent_dir}/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_variables = [\n",
    "    \"snowon_vv\", \"snowon_vh\", \"snowoff_vv\", \"snowoff_vh\"\n",
    "]\n",
    "s2_variables = [\n",
    "    \"AOT\", \"B01\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\",\n",
    "    \"B08\", \"B09\", \"B11\", \"B12\", \"B8A\", \"SCL\", \"WVP\", \"visual\"\n",
    "]\n",
    "s1_s2_vars = [s1_variables, s2_variables]\n",
    "for file in tqdm(files):\n",
    "    skip_file = False\n",
    "    ds = xr.open_dataset(file)\n",
    "    for i, variables in enumerate(s1_s2_vars):\n",
    "        data_array = np.stack([ds[var].values for var in variables], axis=-1)\n",
    "        n_samples = np.prod(data_array.shape[:-1])\n",
    "        n_features = data_array.shape[-1]\n",
    "        reshaped_data = data_array.reshape(n_samples, n_features)\n",
    "        nan_mask = np.isnan(reshaped_data)\n",
    "        if nan_mask.any():\n",
    "            column_means = np.nanmean(reshaped_data, axis=0)\n",
    "            reshaped_data[nan_mask] = np.take(column_means, np.where(nan_mask)[1])\n",
    "        scaler = RobustScaler()\n",
    "        scaled_data = scaler.fit_transform(reshaped_data)\n",
    "        pca = PCA(n_components=4)\n",
    "        pca_result = pca.fit_transform(scaled_data)\n",
    "        if np.isnan(pca.explained_variance_ratio_).any():\n",
    "            skip_file = True\n",
    "            break  # Skip this file\n",
    "        else:\n",
    "            if i == 0:\n",
    "                s1_pc1, s1_pc2 = pca_result[:,0], pca_result[:,1]\n",
    "            else:\n",
    "                s2_pc1, s2_pc2, s2_pc3 = pca_result[:,0], pca_result[:,1],  pca_result[:,2]\n",
    "\n",
    "    if skip_file:\n",
    "        continue\n",
    "\n",
    "    fn = os.path.split(file)[-1]\n",
    "    dowy_1d = calc_dowy(pd.to_datetime(fn.split('_')[4]).dayofyear)\n",
    "    dowy_array = np.full((128, 128), dowy_1d)\n",
    "\n",
    "    new_ds = xr.Dataset({\n",
    "        \"aso_sd\": ([\"x\", \"y\"], ds['aso_sd'].values),\n",
    "        \"fcf\": ([\"x\", \"y\"], ds[\"fcf\"].values),\n",
    "        \"elevation\": ([\"x\", \"y\"], ds[\"elevation\"].values),\n",
    "        \"tri\": ([\"x\", \"y\"], ds[\"tri\"].values),\n",
    "        \"tpi\": ([\"x\", \"y\"], ds[\"tpi\"].values),\n",
    "        \"latitude\": ([\"x\", \"y\"], ds[\"latitude\"].values),\n",
    "        \"longitude\": ([\"x\", \"y\"], ds[\"longitude\"].values),\n",
    "        \"s1_pc1\": ([\"samples\"], s1_pc1),\n",
    "        \"s1_pc2\": ([\"samples\"], s1_pc2),\n",
    "        \"s2_pc1\": ([\"samples\"], s2_pc1),\n",
    "        \"s2_pc2\": ([\"samples\"], s2_pc2),\n",
    "        \"s2_pc3\": ([\"samples\"], s2_pc3),\n",
    "        \"dowy\": ([\"x\", \"y\"], dowy_array)\n",
    "    })\n",
    "\n",
    "    new_ds.to_netcdf(f\"/mnt/c/Users/JackE/uw/courses/aut24/ml_geo/jack_subsets/ncs/{fn}\")\n",
    "\n",
    "    source = f\"/mnt/c/Users/JackE/uw/courses/aut24/ml_geo/final_data/subsets_v4_tif/train/{fn.split('.')[0]}.tif\"\n",
    "    destination = f\"/mnt/c/Users/JackE/uw/courses/aut24/ml_geo/jack_subsets/tifs/{fn.split('.')[0]}.tif\"\n",
    "    shutil.copy(source, destination)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
