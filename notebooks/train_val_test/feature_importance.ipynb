{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fdd84d0-724f-43cc-b500-a1062fc23e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import crunchy_snow.models\n",
    "import crunchy_snow.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5842c9c-0056-4524-9192-28f6ff284bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get paths to data\n",
    "train_data_dir = '/mnt/Backups/gbrench/repos/crunchy-snow/data/subsets_v3/train'\n",
    "train_path_list = glob(f'{train_data_dir}/ASO_50M_SD*.nc')\n",
    "\n",
    "val_data_dir = '/mnt/Backups/gbrench/repos/crunchy-snow/data/subsets_v3/val'\n",
    "val_path_list = glob(f'{val_data_dir}/ASO_50M_SD*.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbc57fcf-0e45-4aad-b986-494f68ea4e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data to be returned by dataloader\n",
    "selected_channels = [\n",
    "    # ASO products\n",
    "    'aso_sd', # ASO lidar snow depth (target dataset)\n",
    "    'aso_gap_map', # gaps in ASO data\n",
    "    \n",
    "    # Sentinel-1 products\n",
    "    'snowon_vv', # snow on Sentinel-1 VV polarization backscatter in dB, closest acquisition to ASO acquisition\n",
    "    'snowon_vh', # snow on Sentinel-1 VH polarization backscatter in dB, closest acquisition to ASO acquisition\n",
    "    'snowoff_vv', # snow off Sentinel-1 VV polarization backscatter in dB, closest acquisition to ASO acquisition\n",
    "    'snowoff_vh', # snow off Sentinel-1 VH polarization backscatter in dB, closest acquisition to ASO acquisition\n",
    "    'snowon_vv_mean', # snow on Sentinel-1 VV polarization backscatter in dB, mean of acquisition in 4 week period around ASO acquisition\n",
    "    'snowon_vh_mean', # snow on Sentinel-1 VH polarization backscatter in dB, mean of acquisition in 4 week period around ASO acquisition\n",
    "    'snowoff_vv_mean', # snow off Sentinel-1 VV polarization backscatter in dB, mean of acquisition in 4 week period around ASO acquisition\n",
    "    'snowoff_vh_mean', # snow off Sentinel-1 VH polarization backscatter in dB, mean of acquisition in 4 week period around ASO acquisition\n",
    "    'snowon_cr', # cross ratio, snowon_vh - snowon_vv\n",
    "    'snowoff_cr', # cross ratio, snowoff_vh - snowoff_vv\n",
    "    'delta_cr', # change in cross ratio, snowon_cr - snowoff_cr\n",
    "    'rtc_gap_map', # gaps in Sentinel-1 data\n",
    "    'rtc_mean_gap_map', # gaps in Sentinel-1 mean data\n",
    "    \n",
    "    # Sentinel-2 products \n",
    "    'aerosol_optical_thickness', # snow on Sentinel-2 aerosol optical thickness band \n",
    "    'coastal_aerosol', # snow on Sentinel-2 coastal aerosol band\n",
    "    'blue', # snow on Sentinel-2 blue band\n",
    "    'green', # snow on Sentinel-2 green band\n",
    "    'red', # snow on Sentinel-2 red band\n",
    "    'red_edge1', # snow on Sentinel-2 red edge 1 band\n",
    "    'red_edge2', # snow on Sentinel-2 red edge 2 band\n",
    "    'red_edge3', # snow on Sentinel-2 red edge 3 band\n",
    "    'nir', # snow on Sentinel-2 near infrared band\n",
    "    'water_vapor', # snow on Sentinel-2 water vapor\n",
    "    'swir1', # snow on Sentinel-2 shortwave infrared band 1\n",
    "    'swir2', # snow on Sentinel-2 shortwave infrared band 2\n",
    "    'scene_class_map', # snow on Sentinel-2 scene classification product\n",
    "    'water_vapor_product', # snow on Sentinel-2 water vapor product\n",
    "    'ndvi', # Normalized Difference Vegetation Index from Sentinel-2\n",
    "    'ndsi', # Normalized Difference Snow Index from Sentinel-2\n",
    "    'ndwi', # Normalized Difference Water Index from Sentinel-2\n",
    "    's2_gap_map', # gaps in Sentinel-2 data\n",
    "\n",
    "    # PROBA-V global land cover dataset (Buchhorn et al., 2020)\n",
    "    'fcf', # fractional forest cover\n",
    "    \n",
    "    # COP30 digital elevation model      \n",
    "    'elevation',\n",
    "\n",
    "    # latitude and longitude\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "\n",
    "    # day of water year\n",
    "    'dowy'\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3117143f-d7ba-4763-84b1-7331a68d6f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(input_channels, epochs, n_layers, max_kernel):\n",
    "    model = crunchy_snow.models.ResDepth(n_input_channels=len(input_channels), depth=n_layers, max_filter_depth=max_kernel)\n",
    "    model.to('cuda');  # Run on GPU\n",
    "    # Define optimizer and loss function\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.0003)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    epochs = epochs\n",
    "    \n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    \n",
    "    # training and validation loop\n",
    "    for epoch in range(epochs):\n",
    "        print(f'\\nStarting epoch {epoch+1}')\n",
    "        epoch_loss = []\n",
    "        val_temp_loss = []\n",
    "    \n",
    "        # Loop through training data with tqdm progress bar\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", unit=\"batch\", ncols=130)\n",
    "        for data_tuple in pbar:\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # read data into dictionary\n",
    "            data_dict = {name: tensor for name, tensor in zip(selected_channels, data_tuple)}\n",
    "            # prepare inputs by concatenating along channel dimension\n",
    "            inputs = torch.cat([data_dict[channel] for channel in input_channels], dim=1).to('cuda')\n",
    "    \n",
    "            # generate prediction\n",
    "            pred_sd = model(inputs)\n",
    "    \n",
    "            # Limit prediction to areas with valid data\n",
    "            pred_sd = torch.where(data_dict['aso_gap_map'].to('cuda') + data_dict['rtc_gap_map'].to('cuda') + data_dict['s2_gap_map'].to('cuda') == 0, pred_sd, torch.zeros_like(pred_sd).to('cuda'))\n",
    "            aso_sd = torch.where(data_dict['aso_gap_map'].to('cuda') + data_dict['rtc_gap_map'].to('cuda') + data_dict['s2_gap_map'].to('cuda')== 0, data_dict['aso_sd'].to('cuda'), torch.zeros_like(pred_sd).to('cuda'))\n",
    "    \n",
    "            # Calculate loss\n",
    "            loss = loss_fn(pred_sd, aso_sd.to('cuda'))\n",
    "            epoch_loss.append(loss.item())\n",
    "    \n",
    "            # Update tqdm progress bar with batch loss\n",
    "            pbar.set_postfix({'batch loss': loss.item(), 'mean epoch loss': np.mean(epoch_loss)})\n",
    "    \n",
    "    \n",
    "            loss.backward()  # Propagate the gradients in backward pass\n",
    "            optimizer.step()\n",
    "    \n",
    "        train_loss.append(np.mean(epoch_loss))\n",
    "        print(f'Training loss: {np.mean(epoch_loss)}')\n",
    "    \n",
    "        # Run model on validation data with tqdm progress bar\n",
    "        for data_tuple in tqdm(val_loader, desc=\"Validation\", unit=\"batch\"):\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                \n",
    "                # read data into dictionary\n",
    "                data_dict = {name: tensor for name, tensor in zip(selected_channels, data_tuple)}\n",
    "                # prepare inputs by concatenating along channel dimension\n",
    "                inputs = torch.cat([data_dict[channel] for channel in input_channels], dim=1).to('cuda')\n",
    "        \n",
    "                # generate prediction\n",
    "                pred_sd = model(inputs)\n",
    "        \n",
    "                # Limit prediction to areas with valid data\n",
    "                pred_sd = torch.where(data_dict['aso_gap_map'].to('cuda') + data_dict['rtc_gap_map'].to('cuda') == 0, pred_sd, torch.zeros_like(pred_sd).to('cuda'))\n",
    "                aso_sd = torch.where(data_dict['aso_gap_map'].to('cuda') + data_dict['rtc_gap_map'].to('cuda') == 0, data_dict['aso_sd'].to('cuda'), torch.zeros_like(pred_sd).to('cuda'))\n",
    "        \n",
    "                # Calculate loss\n",
    "                loss = loss_fn(pred_sd, aso_sd.to('cuda'))\n",
    "                val_temp_loss.append(loss.item())\n",
    "    \n",
    "        val_loss.append(np.mean(val_temp_loss))\n",
    "        print(f'Validation loss: {np.mean(val_temp_loss)}')\n",
    "\n",
    "    return np.min(train_loss), np.min(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a4999f8-8ea1-498c-a8e1-b1beb35709c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input channels for model\n",
    "all_input_channels = [\n",
    "    'snowon_vv',\n",
    "    'snowon_vh',\n",
    "    'snowoff_vv',\n",
    "    'snowoff_vh',\n",
    "    'snowon_cr',\n",
    "    'snowoff_cr',\n",
    "    'delta_cr',\n",
    "    'blue',\n",
    "    'green',\n",
    "    'red',\n",
    "    'nir',\n",
    "    'swir1',\n",
    "    'swir2',\n",
    "    'scene_class_map',\n",
    "    'ndvi',\n",
    "    'ndsi',\n",
    "    'ndwi',\n",
    "    'fcf',\n",
    "    'elevation',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'dowy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4f8520b-1c0c-4fa6-94ac-1fcc1aab40aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample dataset\n",
    "n_imgs = 16\n",
    "train_path_list = random.sample(train_path_list, n_imgs)\n",
    "val_path_list = random.sample(val_path_list, n_imgs)\n",
    "# prepare training and validation dataloaders\n",
    "train_data = crunchy_snow.dataset.Dataset(train_path_list, selected_channels, norm=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=16, shuffle=True)\n",
    "val_data = crunchy_snow.dataset.Dataset(val_path_list, selected_channels, norm=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_data, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae3d1c8-4ffb-444e-9196-3810daa8990d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "trial 1/100\n",
      "trial 1 input channels: ['fcf', 'swir1', 'snowoff_vh', 'ndwi', 'snowoff_cr', 'snowon_vh', 'snowoff_vv', 'ndsi', 'snowon_cr', 'elevation', 'swir2']\n",
      "\n",
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|█████████████████████████████████████| 1/1 [00:04<00:00,  4.96s/batch, batch loss=0.0139, mean epoch loss=0.0139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.01386793702840805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.48s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.006122227292507887\n",
      "\n",
      "Starting epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.42s/batch, batch loss=0.00775, mean epoch loss=0.00775]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.007752183824777603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.88s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.003418389242142439\n",
      "\n",
      "Starting epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.43s/batch, batch loss=0.00495, mean epoch loss=0.00495]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.004946465604007244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.44s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.003097961423918605\n",
      "\n",
      "Starting epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.43s/batch, batch loss=0.00483, mean epoch loss=0.00483]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.004831929225474596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.44s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0038175168447196484\n",
      "\n",
      "Starting epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.45s/batch, batch loss=0.00579, mean epoch loss=0.00579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.005793564021587372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.43s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.004116851836442947\n",
      "\n",
      "Starting epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.45s/batch, batch loss=0.00615, mean epoch loss=0.00615]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.006153309252113104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.43s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.003818458877503872\n",
      "\n",
      "Starting epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.44s/batch, batch loss=0.00574, mean epoch loss=0.00574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.005737831816077232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.44s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.003265687730163336\n",
      "\n",
      "Starting epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.43s/batch, batch loss=0.00498, mean epoch loss=0.00498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.00497992942109704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.42s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.002762323711067438\n",
      "\n",
      "Starting epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.45s/batch, batch loss=0.00425, mean epoch loss=0.00425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.004253816790878773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.43s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0024532070383429527\n",
      "\n",
      "Starting epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████████████████████████████| 1/1 [00:03<00:00,  3.44s/batch, batch loss=0.00374, mean epoch loss=0.00374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.003738784696906805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.43s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0023637106642127037\n",
      "\n",
      "Starting epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████████████████████████████| 1/1 [00:03<00:00,  3.50s/batch, batch loss=0.00348, mean epoch loss=0.00348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.003479021368548274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.15s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.002428196370601654\n",
      "\n",
      "Starting epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████████████████████████████| 1/1 [00:02<00:00,  2.74s/batch, batch loss=0.00341, mean epoch loss=0.00341]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.003411351703107357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.45s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0025427136570215225\n",
      "\n",
      "Starting epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████████████████████████████| 1/1 [00:03<00:00,  3.43s/batch, batch loss=0.00342, mean epoch loss=0.00342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.003424044931307435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.66s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.002614496275782585\n",
      "\n",
      "Starting epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████████████████████████████| 1/1 [00:03<00:00,  3.44s/batch, batch loss=0.00342, mean epoch loss=0.00342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0034181978553533554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.42s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.002589217619970441\n",
      "\n",
      "Starting epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████████████████████████████| 1/1 [00:03<00:00,  3.44s/batch, batch loss=0.00334, mean epoch loss=0.00334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.003335281740874052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.43s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0024556387215852737\n",
      "\n",
      "Starting epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████████████████████████████| 1/1 [00:03<00:00,  3.43s/batch, batch loss=0.00316, mean epoch loss=0.00316]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0031632566824555397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.44s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.002239635679870844\n",
      "\n",
      "Starting epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████████████████████████████| 1/1 [00:03<00:00,  3.42s/batch, batch loss=0.00293, mean epoch loss=0.00293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0029324369970709085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.42s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.001994190737605095\n",
      "\n",
      "Starting epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|████████████████████████████████████| 1/1 [00:03<00:00,  3.44s/batch, batch loss=0.0027, mean epoch loss=0.0027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0026992796920239925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.43s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0017766420496627688\n",
      "\n",
      "Starting epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████████████████████████████| 1/1 [00:03<00:00,  3.44s/batch, batch loss=0.00252, mean epoch loss=0.00252]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0025195854250341654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.44s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0016262579010799527\n",
      "\n",
      "Starting epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████████████████████████████| 1/1 [00:03<00:00,  3.44s/batch, batch loss=0.00242, mean epoch loss=0.00242]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.002424437552690506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.43s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0015477908309549093\n",
      "trial 1 final train loss: 0.002424437552690506, final val loss: 0.0015477908309549093\n",
      "---------------------------------------------------------\n",
      "trial 2/100\n",
      "trial 2 input channels: ['blue', 'red', 'elevation', 'snowoff_vv', 'dowy', 'snowoff_cr', 'snowon_cr', 'snowon_vh', 'scene_class_map', 'fcf', 'swir2']\n",
      "\n",
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.44s/batch, batch loss=0.00914, mean epoch loss=0.00914]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.009136082604527473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.43s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0027455275412648916\n",
      "\n",
      "Starting epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.46s/batch, batch loss=0.00392, mean epoch loss=0.00392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.003918749745935202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.42s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.002608755137771368\n",
      "\n",
      "Starting epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.44s/batch, batch loss=0.00374, mean epoch loss=0.00374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0037361502181738615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.43s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.003588136751204729\n",
      "\n",
      "Starting epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.45s/batch, batch loss=0.00482, mean epoch loss=0.00482]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.004823969677090645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.43s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0034565534442663193\n",
      "\n",
      "Starting epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.46s/batch, batch loss=0.00465, mean epoch loss=0.00465]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.004645613022148609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.43s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.002666451735422015\n",
      "\n",
      "Starting epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|███████████████████████████████████| 1/1 [00:03<00:00,  3.45s/batch, batch loss=0.00368, mean epoch loss=0.00368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0036839160602539778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.44s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.001977604813873768\n",
      "\n",
      "Starting epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|█████████████████████████████████████| 1/1 [00:03<00:00,  3.46s/batch, batch loss=0.0028, mean epoch loss=0.0028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.002796629909425974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.44s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0017495134379714727\n",
      "\n",
      "Starting epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|█████████████████████████████████████| 1/1 [00:03<00:00,  3.47s/batch, batch loss=0.0024, mean epoch loss=0.0024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0024011300411075354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                                                                              | 0/1 [00:00<?, ?batch/s]"
     ]
    }
   ],
   "source": [
    "num_trials = 100\n",
    "exp_dict = {}\n",
    "for trial in range(num_trials):\n",
    "    print('---------------------------------------------------------')\n",
    "    print(f'trial {trial+1}/{num_trials}')\n",
    "    input_channels = random.sample(all_input_channels, 11)\n",
    "    print(f'trial {trial+1} input channels: {input_channels}')\n",
    "    # # subsample dataset\n",
    "    # train_path_list = random.sample(train_path_list, n_imgs)\n",
    "    # val_path_list = random.sample(val_path_list, n_imgs)\n",
    "    # # prepare training and validation dataloaders\n",
    "    # train_data = crunchy_snow.dataset.Dataset(train_path_list, selected_channels, norm=True)\n",
    "    # train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=16, shuffle=True)\n",
    "    # val_data = crunchy_snow.dataset.Dataset(val_path_list, selected_channels, norm=True)\n",
    "    # val_loader = torch.utils.data.DataLoader(dataset=val_data, batch_size=16, shuffle=True)\n",
    "    # train model\n",
    "    final_train_loss, final_val_loss = train_model(input_channels, epochs=20, n_layers=5, max_kernel=1024)\n",
    "    print(f'trial {trial+1} final train loss: {final_train_loss}, final val loss: {final_val_loss}')\n",
    "    exp_dict[trial+1] = [input_channels, final_train_loss, final_val_loss]\n",
    "    # save experiments \n",
    "    with open(f'../../loss/ResDepth_feature_sel_loss_v1.pkl', 'wb') as f:\n",
    "        pickle.dump(exp_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19bbe9c-724e-47aa-bc13-45887ea0eba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../../loss/ResDepth_feature_sel_loss.pkl', 'rb') as f:\n",
    "        exp_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f49c462-f67f-4099-81f6-d1c411972767",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_channel_performance = {}\n",
    "val_channel_performance = {}\n",
    "all_values = {}\n",
    "for channel in all_input_channels:\n",
    "    train_loss_w_channel = []\n",
    "    val_loss_w_channel = []\n",
    "    train_loss_wo_channel = []\n",
    "    val_loss_wo_channel = []\n",
    "    for trial in exp_dict.keys():\n",
    "        if channel in exp_dict[trial][0]:\n",
    "            train_loss_w_channel.append(exp_dict[trial][1])\n",
    "            val_loss_w_channel.append(exp_dict[trial][2])\n",
    "        else:\n",
    "            train_loss_wo_channel.append(exp_dict[trial][1])\n",
    "            val_loss_wo_channel.append(exp_dict[trial][2])\n",
    "    train_loss_diff = np.mean(train_loss_wo_channel) - np.mean(train_loss_w_channel)\n",
    "    val_loss_diff = np.mean(val_loss_wo_channel) - np.mean(val_loss_w_channel)\n",
    "    train_channel_performance[channel] = train_loss_diff\n",
    "    val_channel_performance[channel] = val_loss_diff\n",
    "    all_values[channel] = [train_loss_w_channel, train_loss_wo_channel, val_loss_w_channel, val_loss_wo_channel]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'channels': train_channel_performance.keys(),\n",
    "    'train_loss_diff': train_channel_performance.values(),\n",
    "    'val_loss_diff': val_channel_performance.values()\n",
    "})\n",
    "\n",
    "df = df.sort_values('val_loss_diff', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb1c59a-db41-4d86-a895-d94569f07734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum length of the lists\n",
    "max_len = max(max(len(lst) for lst in metrics) for metrics in all_values.values())\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "rows = []\n",
    "for channel, metrics in all_values.items():\n",
    "    for i in range(max_len):\n",
    "        row = [channel]\n",
    "        for metric in metrics:\n",
    "            if i < len(metric):\n",
    "                row.append(metric[i])\n",
    "            else:\n",
    "                row.append(np.nan)\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows, columns=['channel', 'train_mse_w', 'train_mse_wo', 'val_mse_w', 'val_mse_wo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527f312f-b36e-42f3-8499-f3d9a211f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "results = []\n",
    "\n",
    "# Perform Mann–Whitney U tests for each channel\n",
    "for channel in df['channel'].unique():\n",
    "    channel_data = df[df['channel'] == channel]\n",
    "    metric_1 = channel_data['train_mse_w'].dropna()\n",
    "    metric_2 = channel_data['train_mse_wo'].dropna()\n",
    "    metric_3 = channel_data['val_mse_w'].dropna()\n",
    "    metric_4 = channel_data['val_mse_wo'].dropna()\n",
    "    \n",
    "    # Mann–Whitney U test for metrics 1 and 2\n",
    "    stat_train, p_train = mannwhitneyu(metric_1, metric_2)\n",
    "    \n",
    "    # Mann–Whitney U test for metrics 3 and 4\n",
    "    stat_val, p_val = mannwhitneyu(metric_3, metric_4)\n",
    "    \n",
    "    # Append results to the list\n",
    "    results.append([channel, p_train, p_val])\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['channel', 'train', 'val'])\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a531e082-7037-43fc-b031-c2675d10f143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "f, ax = plt.subplots(nrows=2, ncols=1, figsize=(10, 8))\n",
    "\n",
    "# Top plot: Performance metrics 1 and 2\n",
    "sns.boxplot(x='channel', y='value', hue='metric', data=pd.melt(df, id_vars=['channel'], value_vars=['train_mse_w', 'train_mse_wo'], var_name='metric'), ax=ax[0])\n",
    "ax[0].set_title('training performance with and without channel')\n",
    "ax[0].set_ylabel('MSE')\n",
    "ax[0].set_xlabel('')\n",
    "ax[0].tick_params(axis='x', rotation=90)\n",
    "ax[0].set_ylim(None, 0.0010)\n",
    "\n",
    "# Bottom plot: Performance metrics 3 and 4\n",
    "sns.boxplot(x='channel', y='value', hue='metric', data=pd.melt(df, id_vars=['channel'], value_vars=['val_mse_w', 'val_mse_wo'], var_name='metric'), ax=ax[1])\n",
    "ax[1].set_title('validation performance with and without channel')\n",
    "ax[1].set_ylabel('MSE')\n",
    "ax[1].set_xlabel('')\n",
    "ax[1].tick_params(axis='x', rotation=90)\n",
    "ax[1].set_ylim(None, 0.0010)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aad18c7-e2f8-4dca-b34b-ec68985ba189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the position of the bars on the x-axis\n",
    "bar_width = 0.35\n",
    "r1 = np.arange(len(df['channels']))\n",
    "r2 = [x + bar_width for x in r1]\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "ax.bar(r1, df['train_loss_diff'], color='blue', width=bar_width, edgecolor='grey', label='change in training MSE')\n",
    "ax.bar(r2, df['val_loss_diff'], color='orange', width=bar_width, edgecolor='grey', label='change in validation MSE')\n",
    "# Add labels\n",
    "ax.set_xlabel('channels')\n",
    "ax.set_xticks([r + bar_width/2 for r in range(len(df['channels']))])\n",
    "ax.set_xticklabels(df['channels'], rotation=90)\n",
    "ax.set_ylabel('change in MSE loss', fontweight='bold')\n",
    "ax.set_title('mean change in final MSE when channels are included')\n",
    "# Add legend\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af72479b-0d32-42b1-ad8a-94a45a205208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot\n",
    "# Determine the min and max values for the axes\n",
    "min_value = min(min(df['val_loss_diff']), min(df['train_loss_diff']))\n",
    "max_value = max(max(df['val_loss_diff']), max(df['train_loss_diff']))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.axvline(0, alpha=0.3)\n",
    "ax.axhline(0, alpha=0.3)\n",
    "ax.plot([min_value, max_value], [min_value, max_value], color='grey', linestyle='--', linewidth=1)\n",
    "\n",
    "for channel in df['channels']:\n",
    "    ax.scatter(df.loc[df['channels'] == channel, 'val_loss_diff'], df.loc[df['channels'] == channel, 'train_loss_diff'], label=channel)\n",
    "\n",
    "# Add labels\n",
    "ax.set_xlabel('change in validation MSE', fontweight='bold')\n",
    "ax.set_ylabel('change in training MSE', fontweight='bold')\n",
    "ax.set_title('mean improvement in final MSE when channels are included')\n",
    "ax.set_aspect('equal')\n",
    "padding = 0.00001\n",
    "ax.set_xlim(min_value-padding, max_value+padding)\n",
    "ax.set_ylim(min_value-padding, max_value+padding)\n",
    "\n",
    "# Add legend\n",
    "ax.legend(title='channels', bbox_to_anchor=(1.05, 1), loc='upper left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:crunchy-snow] *",
   "language": "python",
   "name": "conda-env-crunchy-snow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
