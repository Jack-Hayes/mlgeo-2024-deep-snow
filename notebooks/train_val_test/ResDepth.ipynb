{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2abdbcd-fabd-461a-9578-8e5a30c3875d",
   "metadata": {},
   "source": [
    "# Train ResDepth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb91f89f-30eb-4e9f-9eca-52200723d705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import crunchy_snow.models\n",
    "import crunchy_snow.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef112a5c-bfb2-45b3-ba84-6793ab474f72",
   "metadata": {},
   "source": [
    "## Prepare dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "291032ba-7397-4881-a347-23fe3dfe142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get paths to data\n",
    "train_data_dir = '/mnt/Backups/gbrench/repos/crunchy-snow/data/subsetsv1/train'\n",
    "train_path_list = glob(f'{train_data_dir}/ASO_50M_SD*.nc')[0:128]\n",
    "\n",
    "val_data_dir = '/mnt/Backups/gbrench/repos/crunchy-snow/data/subsetsv1/val'\n",
    "val_path_list = glob(f'{val_data_dir}/ASO_50M_SD*.nc')[0:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56e509d6-4e62-46ed-b44d-c2adb318c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data to be returned by dataloader\n",
    "selected_channels = ['aso_sd', # ASO lidar snow depth (target dataset)\n",
    "                     'snowon_vv', # snow on Sentinel-1 VV polarization backscatter\n",
    "                     'snowon_vh', # snow on Sentinel-1 VH polarization backscatter\n",
    "                     'snowoff_vv', # snow off Sentinel-1 VV polarization backscatter\n",
    "                     'snowoff_vh', # snow off Sentinel-1 VH polarization backscatter\n",
    "                     'blue', # snow on Sentinel-2 blue band\n",
    "                     'green', # snow on Sentinel-2 green band\n",
    "                     'red', # snow on Sentinel-2 red band\n",
    "                     'fcf', # fractional forest cover\n",
    "                     'elevation', # elevation (COP30 DEM)\n",
    "                     'aso_gap_map', # gaps in ASO data\n",
    "                     'rtc_gap_map', # gaps in Sentinel-1 data\n",
    "                     'ndvi', # Normalized Difference Vegetation Index from Sentinel-2\n",
    "                     'ndsi', # Normalized Difference Snow Index from Sentinel-2\n",
    "                     'ndwi' # Normalized Difference Water Index from Sentinel-2\n",
    "                    ]\n",
    "\n",
    "# prepare training and validation dataloaders\n",
    "train_data = crunchy_snow.dataset.Dataset(train_path_list, selected_channels, norm=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=16, shuffle=True)\n",
    "val_data = crunchy_snow.dataset.Dataset(val_path_list, selected_channels, norm=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1560a9fc-a3c1-4cc4-bba3-3aa18eaeb5ec",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acc61b5d-3f98-45ed-96c7-fe083a805416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model\n",
    "model = crunchy_snow.models.ResDepth(input_channels=12)\n",
    "model.to('cuda');  # Run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a14c73d-9989-4414-80ec-052fe0ce8f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting epoch 1\n",
      "Training loss: 0.001360931433737278\n",
      "Validation loss: 0.005105434335709813\n",
      "\n",
      "Starting epoch 2\n",
      "Training loss: 0.0013276629251777194\n",
      "Validation loss: 0.005108741259088459\n",
      "\n",
      "Starting epoch 3\n",
      "Training loss: 0.0013279019767651334\n",
      "Validation loss: 0.0051087626817245685\n",
      "\n",
      "Starting epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "epochs = 50\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'\\nStarting epoch {epoch+1}')\n",
    "    epoch_loss = []\n",
    "    val_temp_loss = []\n",
    "\n",
    "    # Loop through training data\n",
    "    for (aso_sd, snowon_vv, snowon_vh, snowoff_vv, snowoff_vh, blue, green, red, fcf, elevation, aso_gap_map, rtc_gap_map, ndvi, ndsi, ndwi) in train_loader:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Concatenate all feature channels\n",
    "        inputs = torch.cat((snowon_vv, snowon_vh, snowoff_vv, snowoff_vh, blue, green, red, fcf, elevation, ndvi, ndsi, ndwi), dim=1).to('cuda')\n",
    "        pred_sd = torch.clamp(model(inputs), 0, 1)  # Generate predictions\n",
    "\n",
    "        # Limit prediction to areas with valid data\n",
    "        pred_sd = torch.where(aso_gap_map.to('cuda') + rtc_gap_map.to('cuda') == 0, pred_sd, torch.zeros_like(pred_sd).to('cuda'))\n",
    "        aso_sd = torch.where(aso_gap_map.to('cuda') + rtc_gap_map.to('cuda') == 0, aso_sd.to('cuda'), torch.zeros_like(pred_sd).to('cuda'))\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(pred_sd, aso_sd.to('cuda'))\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "        loss.backward()  # Propagate the gradients in backward pass\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss.append(np.mean(epoch_loss))\n",
    "    print(f'Training loss: {np.mean(epoch_loss)}')\n",
    "\n",
    "    # Run model on validation data\n",
    "    for (aso_sd, snowon_vv, snowon_vh, snowoff_vv, snowoff_vh, blue, green, red, fcf, elevation, aso_gap_map, rtc_gap_map, ndvi, ndsi, ndwi) in val_loader:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            \n",
    "            # Concatenate all feature channels\n",
    "            inputs = torch.cat((snowon_vv, snowon_vh, snowoff_vv, snowoff_vh, blue, green, red, fcf, elevation, ndvi, ndsi, ndwi), dim=1).to('cuda')\n",
    "            pred_sd = torch.clamp(model(inputs), 0, 1)  # Generate predictions\n",
    "    \n",
    "            # Limit prediction to areas with valid data\n",
    "            pred_sd = torch.where(aso_gap_map.to('cuda') + rtc_gap_map.to('cuda') == 0, pred_sd, torch.zeros_like(pred_sd).to('cuda'))\n",
    "            aso_sd = torch.where(aso_gap_map.to('cuda') + rtc_gap_map.to('cuda') == 0, aso_sd.to('cuda'), torch.zeros_like(pred_sd).to('cuda'))\n",
    "\n",
    "            loss = loss_fn(pred_sd, aso_sd.to('cuda'))\n",
    "            val_temp_loss.append(loss.item())\n",
    "\n",
    "    val_loss.append(np.mean(val_temp_loss))\n",
    "    print(f'Validation loss: {np.mean(val_temp_loss)}')\n",
    "    \n",
    "    # # save model\n",
    "    # torch.save(model.state_dict(), f'../../weights/ResDepth_v0')\n",
    "\n",
    "    # # save loss \n",
    "    # with open('../../loss/ResDepth_v0_val_loss.pkl', 'wb') as f:\n",
    "    #     pickle.dump(val_loss, f)\n",
    "        \n",
    "    # with open('../../loss/ResDepth_v0_train_loss.pkl', 'wb') as f:\n",
    "    #     pickle.dump(train_loss, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb29e3a-bb96-4892-b110-b32040497bea",
   "metadata": {},
   "source": [
    "## Examine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7c8e3e-f2ce-4327-bb9c-89d7c73ec254",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot loss over all epochs\n",
    "f, ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(train_loss, label='training')\n",
    "ax.plot(val_loss, label='validation')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('L1 loss')\n",
    "ax.set_title('Loss')\n",
    "ax.legend()\n",
    "# plt.savefig('../../figs/ResDepth_v0_loss1.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da42364-67f8-43d8-ad35-6739e9f5cb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model outputs\n",
    "num_images = 1\n",
    "\n",
    "for i, (aso_sd, snowon_vv, snowon_vh, snowoff_vv, snowoff_vh, blue, green, red, fcf, elevation, aso_gap_map, rtc_gap_map, ndvi, ndsi, ndwi) in enumerate(val_loader):\n",
    "    if i < num_images:\n",
    "        with torch.no_grad():\n",
    "            # Concatenate all feature channels\n",
    "            inputs = torch.cat((snowon_vv, snowon_vh, snowoff_vv, snowoff_vh, blue, green, red, fcf, elevation, ndvi, ndsi, ndwi), dim=1).to('cuda')\n",
    "            pred_sd = model(inputs)  # Generate predictions using the model\n",
    "            pred_sd = pred_sd.to('cpu')\n",
    "            \n",
    "            f, ax = plt.subplots(3, 3, figsize=(15, 15))\n",
    "            ax[0, 0].imshow(pred_sd.squeeze(), cmap='Blues', vmin=0, vmax=0.4, interpolation=None)\n",
    "            ax[0, 0].set_title('Predicted Snow Depth')\n",
    "            ax[0, 1].imshow(aso_sd.squeeze(), cmap='Blues', vmin=0, vmax=0.4, interpolation=None)\n",
    "            ax[0, 1].set_title('ASO Lidar Snow Depth')\n",
    "            ax[0, 2].imshow(elevation.squeeze(), cmap='viridis', interpolation='none')\n",
    "            ax[0, 2].set_title('Copernicus DEM')\n",
    "            ax[1, 0].imshow(fcf.squeeze(), cmap='Greens', interpolation='none')\n",
    "            ax[1, 0].set_title('Fractional Forest Cover')\n",
    "            norm_max = np.max([green.max(), red.max(), blue.max()])  # There are better ways to do this\n",
    "            ax[1, 1].imshow(torch.cat((red.squeeze()[:, :, None] / norm_max, green.squeeze()[:, :, None] / norm_max, blue.squeeze()[:, :, None] / norm_max), 2).squeeze(), interpolation='none')\n",
    "            ax[1, 1].set_title('True Color Image')\n",
    "            ax[1, 2].imshow(aso_gap_map.squeeze() + rtc_gap_map.squeeze(), cmap='Purples', interpolation='none')\n",
    "            ax[1, 2].set_title('ASO and RTC Gaps')\n",
    "            ax[2, 0].imshow(ndvi.squeeze(), cmap='YlGn', interpolation='none')\n",
    "            ax[2, 0].set_title('NDVI')\n",
    "            ax[2, 1].imshow(ndsi.squeeze(), cmap='BuPu', interpolation='none')\n",
    "            ax[2, 1].set_title('NDSI')\n",
    "            ax[2, 2].imshow(ndwi.squeeze(), cmap='YlGnBu', interpolation='none')\n",
    "            ax[2, 2].set_title('NDWI')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            # plt.savefig('../../figs/ResDepth_v0_pred_raw.png', dpi=300)\n",
    "    else:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:crunchy-snow] *",
   "language": "python",
   "name": "conda-env-crunchy-snow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
