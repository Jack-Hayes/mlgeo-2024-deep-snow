{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e78065a-d4e4-42b8-a042-71a850406192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "import rasterio as rio\n",
    "import rioxarray as rxr\n",
    "from rioxarray.merge import merge_arrays\n",
    "from urllib.request import urlretrieve\n",
    "from pyproj import Proj, transform\n",
    "from os.path import basename, exists, expanduser, join\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "import odc.stac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2dac2c1-a9e1-49e4-ba1e-ac94d86900b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = {\n",
    "    \"type\": \"Polygon\",\n",
    "    \"coordinates\":  [\n",
    "          [\n",
    "            [-105.8700465489473,\n",
    "             40.635037173883745],\n",
    "            [-105.8700465489473,\n",
    "             39.94338694564476],\n",
    "            [-105.44917735019361,\n",
    "              39.94338694564476],\n",
    "            [-105.44917735019361,\n",
    "             40.635037173883745],\n",
    "            [-105.8700465489473,\n",
    "              40.635037173883745]\n",
    "          ]\n",
    "        ]\n",
    "}\n",
    "\n",
    "aoi_gpd = gpd.GeoDataFrame({'geometry':[shape(aoi)]}).set_crs(crs=\"EPSG:4326\")\n",
    "\n",
    "crs = aoi_gpd.estimate_utm_crs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69e22577-137e-4fad-afdb-181f0f83c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowon_date_range = \"2024-03-01/2024-04-01\"\n",
    "snowoff_date_range = \"2023-09-01/2023-10-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b89b4b1-ea52-47ef-ad12-d39753beb8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "stac = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ec7d1a-afa8-48c6-a1d2-a26e230da303",
   "metadata": {},
   "source": [
    "## grab S1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dba594ed-34eb-4fc6-8965-4e13fa3f5953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned 10 acquisitions\n"
     ]
    }
   ],
   "source": [
    "# snow on ds\n",
    "search = stac.search(\n",
    "    intersects=aoi,\n",
    "    datetime=snowon_date_range,\n",
    "    collections=[\"sentinel-1-rtc\"]\n",
    ")\n",
    "\n",
    "items = search.item_collection()\n",
    "\n",
    "snowon_s1_ds = odc.stac.load(items,chunks={\"x\": 2048, \"y\": 2048},\n",
    "                             crs=crs,\n",
    "                             resolution=50,\n",
    "                             bbox=aoi_gpd.total_bounds,\n",
    "                             groupby='sat:absolute_orbit')\n",
    "\n",
    "print(f\"Returned {len(snowon_s1_ds.time)} acquisitions\")\n",
    "\n",
    "# limit to morning acquisitions\n",
    "snowon_s1_ds = snowon_s1_ds.where(snowon_s1_ds.time.dt.hour > 11, drop=True)\n",
    "\n",
    "# compute median\n",
    "snowon_s1_ds = snowon_s1_ds.median(dim='time').squeeze().compute()\n",
    "\n",
    "# rename variables\n",
    "snowon_s1_ds = snowon_s1_ds.rename({\n",
    "    'vv': 'snowon_vv',\n",
    "    'vh': 'snowon_vh'\n",
    "})\n",
    "\n",
    "# # mask negative areas\n",
    "# snowon_s1_ds = snowon_s1_ds.where(snowon_s1_ds.vh > 0)\n",
    "# snowon_s1_ds = snowon_s1_ds.where(snowon_s1_ds.vv > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd155190-dca0-4f7d-b44c-2f9943744cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned 10 acquisitions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/rasterio/warp.py:344: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  _reproject(\n"
     ]
    }
   ],
   "source": [
    "# snow off ds \n",
    "search = stac.search(\n",
    "    intersects=aoi,\n",
    "    datetime=snowoff_date_range,\n",
    "    collections=[\"sentinel-1-rtc\"]\n",
    ")\n",
    "\n",
    "items = search.item_collection()\n",
    "\n",
    "snowoff_s1_ds = odc.stac.load(items,chunks={\"x\": 2048, \"y\": 2048},\n",
    "                              like=snowon_s1_ds,\n",
    "                              groupby='sat:absolute_orbit')\n",
    "\n",
    "print(f\"Returned {len(snowoff_s1_ds.time)} acquisitions\")\n",
    "\n",
    "# limit to morning acquisitions\n",
    "snowoff_s1_ds = snowoff_s1_ds.where(snowoff_s1_ds.time.dt.hour > 11, drop=True)\n",
    "\n",
    "# # mask negative areas\n",
    "# snowoff_s1_ds = snowoff_s1_ds.where(snowoff_s1_ds.vh > 0)\n",
    "# snowoff_s1_ds = snowoff_s1_ds.where(snowoff_s1_ds.vv > 0)\n",
    "\n",
    "# compute median\n",
    "snowoff_s1_ds = snowoff_s1_ds.median(dim='time').squeeze().compute()\n",
    "\n",
    "snowoff_s1_ds = snowoff_s1_ds.rename({\n",
    "    'vv': 'snowoff_vv',\n",
    "    'vh': 'snowoff_vh'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760297a6-f40c-4733-97fd-dcfbc6be1801",
   "metadata": {},
   "source": [
    "## grab s2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "845c4341-69e8-4f4d-8ab8-b6b6b45e3b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned 3 acquisitions\n"
     ]
    }
   ],
   "source": [
    "search = stac.search(\n",
    "    intersects=aoi,\n",
    "    datetime=snowon_date_range,\n",
    "    collections=[\"sentinel-2-l2a\"],\n",
    "    query={\"eo:cloud_cover\": {\"lt\": 25}},\n",
    ")\n",
    "\n",
    "items = search.item_collection()\n",
    "\n",
    "s2_ds = odc.stac.load(items,chunks={\"x\": 2048, \"y\": 2048},\n",
    "                      like=snowon_s1_ds,\n",
    "                      groupby='solar_day').where(lambda x: x > 0, other=np.nan)\n",
    "\n",
    "print(f\"Returned {len(s2_ds.time)} acquisitions\")\n",
    "\n",
    "# compute median\n",
    "s2_ds = s2_ds.median(dim='time').squeeze().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eee142-4831-44bc-bcf1-097e2ad72c95",
   "metadata": {},
   "source": [
    "## grab cop30 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56490f9d-465b-4b28-b0fc-21c02c191718",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = stac.search(\n",
    "    collections=[\"cop-dem-glo-30\"],\n",
    "    intersects=aoi\n",
    ")\n",
    "\n",
    "items = search.item_collection()\n",
    "    \n",
    "data = []\n",
    "for item in items:\n",
    "    dem_path = planetary_computer.sign(item.assets['data']).href\n",
    "    data.append(rxr.open_rasterio(dem_path))\n",
    "cop30_da = merge_arrays(data)\n",
    "cop30_ds = cop30_da.rename('elevation').squeeze().to_dataset()\n",
    "\n",
    "# reproject to match radar dataset\n",
    "cop30_ds = cop30_ds.rio.reproject_match(snowon_s1_ds, resampling=rio.enums.Resampling.bilinear).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8313a700-7da2-427e-a3ff-a2e3450ba0ce",
   "metadata": {},
   "source": [
    "## grab fcf data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "605de344-543b-4802-b232-33179410d9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists, skipping\n"
     ]
    }
   ],
   "source": [
    "def url_download(url, out_fp, overwrite = False):\n",
    "    # check if file already exists\n",
    "    if not exists(out_fp) or overwrite == True:\n",
    "            urlretrieve(url, out_fp)\n",
    "    # if already exists. skip download.\n",
    "    else:\n",
    "        print('file already exists, skipping')\n",
    "\n",
    "def download_fcf(out_fp):\n",
    "    # this is the url from Lievens et al. 2021 paper\n",
    "    fcf_url = 'https://zenodo.org/record/3939050/files/PROBAV_LC100_global_v3.0.1_2019-nrt_Tree-CoverFraction-layer_EPSG-4326.tif'\n",
    "    # download just forest cover fraction to out file\n",
    "    url_download(fcf_url, out_fp)\n",
    "\n",
    "fcf_path ='/tmp/fcf_global.tif'\n",
    "download_fcf(fcf_path)\n",
    "\n",
    "# open as dataArray and return\n",
    "fcf_ds = rxr.open_rasterio(fcf_path)\n",
    "\n",
    "# clip to aoi\n",
    "fcf_ds = fcf_ds.rio.clip_box(*aoi_gpd.total_bounds,crs=\"EPSG:4326\") \n",
    "\n",
    "# promote to dataset\n",
    "fcf_ds = fcf_ds.rename('fcf').squeeze().to_dataset()\n",
    "\n",
    "# reproject to match radar dataset\n",
    "fcf_ds = fcf_ds.rio.reproject_match(snowon_s1_ds, resampling=rio.enums.Resampling.bilinear)\n",
    "\n",
    "# set values above 100 to nodata\n",
    "fcf_ds['fcf'] = fcf_ds['fcf'].where(fcf_ds['fcf'] <= 100, np.nan)/100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ab0206-9524-4fa4-a873-08dc910bd468",
   "metadata": {},
   "source": [
    "## combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba1bf69e-f466-4b00-8d75-4978527019b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_list = [snowon_s1_ds, snowoff_s1_ds, s2_ds, cop30_ds, fcf_ds]\n",
    "ds = xr.merge(ds_list, compat='override', join='override').squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae057f96-adc8-4813-88d9-78579fa81862",
   "metadata": {},
   "source": [
    "## calculate additional data variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31608a02-215c-4087-9502-bafc6a9a72a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cross ratios\n",
    "def db_scale(x, epsilon=1e-10):\n",
    "    # Add epsilon only where x is zero\n",
    "    x_with_epsilon = np.where(x==0, epsilon, x)\n",
    "    # Calculate the logarithm\n",
    "    log_x = 10 * np.log10(x_with_epsilon)\n",
    "    # Set the areas where x was originally zero back to zero\n",
    "    log_x[x==0] = 0\n",
    "    return log_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97b5f0cf-e228-4833-a621-e21312b17293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# radar data variables\n",
    "# convert to decibels\n",
    "ds['snowon_vv'] = (('y', 'x'), db_scale(ds['snowon_vv']))\n",
    "ds['snowon_vh'] =  (('y', 'x'),db_scale(ds['snowon_vh']))\n",
    "ds['snowoff_vv'] =  (('y', 'x'),db_scale(ds['snowoff_vv']))\n",
    "ds['snowoff_vh'] =  (('y', 'x'),db_scale(ds['snowoff_vh']))\n",
    "\n",
    "# calculate variables\n",
    "ds['snowon_cr'] = ds['snowon_vh'] - ds['snowon_vv']\n",
    "ds['snowoff_cr'] = ds['snowoff_vh'] - ds['snowoff_vv']\n",
    "ds['delta_cr'] = ds['snowon_cr'] - ds['snowoff_cr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20377431-6710-47f6-a770-d7044f3c5d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s2 band indices\n",
    "ds['ndvi'] = (ds['B08'] - ds['B04'])/(ds['B08'] + ds['B04'])\n",
    "ds['ndsi'] = (ds['B03'] - ds['B11'])/(ds['B03'] + ds['B11'])\n",
    "ds['ndwi'] = (ds['B03'] - ds['B08'])/(ds['B03'] + ds['B08'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d1cc5fe-2dd0-41b5-8eed-ee7c007affa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latitude, longitude\n",
    "# define projections\n",
    "utm_proj = Proj(proj='utm', zone=crs.name[-3:-1], ellps='WGS84') ## NOTE hardcoded utm for now, adjust before use\n",
    "wgs84_proj = Proj(proj='latlong', datum='WGS84')\n",
    "\n",
    "x, y = np.meshgrid(ds['x'].values, ds['y'].values)\n",
    "lon, lat = transform(utm_proj, wgs84_proj, x, y)\n",
    "ds['latitude'] = (('y', 'x'), lat)\n",
    "ds['longitude'] = (('y', 'x'), lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdccf312-0535-4e80-b515-efea997d1385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dowy\n",
    "# def calc_dowy(doy):\n",
    "#     'calculate day of water year from day of year'\n",
    "#     if doy < 274:\n",
    "#         dowy = doy + (365-274)\n",
    "#     elif doy >= 274:\n",
    "#         dowy = doy-274\n",
    "#     return dowy\n",
    "\n",
    "# ## NOTE think about date and fix this\n",
    "# dowy_1d = calc_dowy(pd.to_datetime(fn.split('_')[4]).dayofyear)\n",
    "# dowy = torch.full_like(aso_sd, dowy_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5816be9a-400e-4320-882a-aa790b7f2b83",
   "metadata": {},
   "source": [
    "## write out to data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edf0bb0f-a1bc-4137-bba1-40cfecd4fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf(f'../../data/application_tmp/RMNP.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
